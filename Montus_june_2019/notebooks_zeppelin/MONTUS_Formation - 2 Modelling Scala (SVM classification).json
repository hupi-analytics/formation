{"paragraphs":[{"text":"%sh pi demo1.hupi.io","user":"anonymous","dateUpdated":"2019-06-13T15:45:17+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"bash: ping: command not found\n"},{"type":"TEXT","data":"ExitValue: 127"}]},"apps":[],"jobName":"paragraph_1560440665812_-1392649293","id":"20190613-154425_1415820730","dateCreated":"2019-06-13T15:44:25+0000","dateStarted":"2019-06-13T15:45:03+0000","dateFinished":"2019-06-13T15:45:03+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17687"},{"text":"%md\n# Import libraries","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Import libraries</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210756_1469881582","id":"20190611-120411_178188615","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17688"},{"text":"import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD}\r\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\r\nimport org.apache.spark.mllib.regression._\r\nimport org.apache.spark.mllib.linalg._\r\nimport org.apache.hadoop.fs.Path","user":"anonymous","dateUpdated":"2019-06-14T07:33:18+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD}\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\nimport org.apache.spark.mllib.regression._\nimport org.apache.spark.mllib.linalg._\nimport org.apache.hadoop.fs.Path\n"}]},"apps":[],"jobName":"paragraph_1560422210757_-911005849","id":"20190611-123627_339348215","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-14T07:33:18+0000","dateFinished":"2019-06-14T07:33:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17689"},{"text":"%md\n# Parameters","user":"anonymous","dateUpdated":"2019-06-13T13:21:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Parameters</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1560432064804_732945176","id":"20190613-132104_1803223495","dateCreated":"2019-06-13T13:21:04+0000","dateStarted":"2019-06-13T13:21:11+0000","dateFinished":"2019-06-13T13:21:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17690"},{"text":"val HdfsUrl = \"hdfs://hupi-factory-02-01-01.factory02.viet.cloud-torus.com:8020/\"\nval dataRepo = \"user/factory02/formation_hupi/wine.csv\"\nval saveRepo = \"user/factory02/formation_hupi/models/\"\nval saveAddress = HdfsUrl + saveRepo + \"svm_model\"\n\nval savePath = new Path(saveAddress)","user":"anonymous","dateUpdated":"2019-06-14T07:33:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"HdfsUrl: String = hdfs://hupi-factory-02-01-01.factory02.viet.cloud-torus.com:8020/\ndataRepo: String = user/factory02/formation_hupi/wine.csv\nsaveRepo: String = user/factory02/formation_hupi/models/\nsaveAddress: String = hdfs://hupi-factory-02-01-01.factory02.viet.cloud-torus.com:8020/user/factory02/formation_hupi/models/svm_model\nsavePath: org.apache.hadoop.fs.Path = hdfs://hupi-factory-02-01-01.factory02.viet.cloud-torus.com:8020/user/factory02/formation_hupi/models/svm_model\n"}]},"apps":[],"jobName":"paragraph_1560432112060_-1774869595","id":"20190613-132152_667110088","dateCreated":"2019-06-13T13:21:52+0000","dateStarted":"2019-06-14T07:33:23+0000","dateFinished":"2019-06-14T07:33:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17691"},{"text":"%md\n# To avoid duplicates in HDFS\n\nBecause we need to write the new model back to HDFS, so we need to remove firstly the old model (with the same name) in HDFS\n","user":"anonymous","dateUpdated":"2019-06-13T13:37:25+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>To avoid duplicates in HDFS</h1>\n<p>Because we need to write the new model back to HDFS, so we need to remove firstly the old model (with the same name) in HDFS</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560432072660_-2051887260","id":"20190613-132112_1432577381","dateCreated":"2019-06-13T13:21:12+0000","dateStarted":"2019-06-13T13:37:25+0000","dateFinished":"2019-06-13T13:37:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17692"},{"text":"val conf = sc.hadoopConfiguration \nval fs = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(HdfsUrl), conf)","user":"anonymous","dateUpdated":"2019-06-14T07:33:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"conf: org.apache.hadoop.conf.Configuration = Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml\nfs: org.apache.hadoop.fs.FileSystem = DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-248896946_78, ugi=root (auth:SIMPLE)]]\n"}]},"apps":[],"jobName":"paragraph_1560432092018_-1206064563","id":"20190613-132132_689056033","dateCreated":"2019-06-13T13:21:32+0000","dateStarted":"2019-06-14T07:33:27+0000","dateFinished":"2019-06-14T07:33:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17693"},{"text":"// delete the svm model if it existed already\r\nfs.delete(new Path(\"hdfs://hupi-factory-02-01-01.factory02.viet.cloud-torus.com:8020/user/factory02/formation_hupi/models\"),true)","user":"anonymous","dateUpdated":"2019-06-14T07:34:13+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res14: Boolean = true\n"}]},"apps":[],"jobName":"paragraph_1560432103969_1534139843","id":"20190613-132143_1876772701","dateCreated":"2019-06-13T13:21:43+0000","dateStarted":"2019-06-14T07:34:13+0000","dateFinished":"2019-06-14T07:34:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17694"},{"text":"%md\n# Load data from HDFS\n\nHere, we use dataset wine.csv that contains chemical analysis of wines grown in the same region in Italy but derived from two different cultivars. This is a sample from dataset wine.data from UCI https://archive.ics.uci.edu/ml/datasets/wine","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Load data from HDFS</h1>\n<p>Here, we use dataset wine.csv that contains chemical analysis of wines grown in the same region in Italy but derived from two different cultivars. This is a sample from dataset wine.data from UCI <a href=\"https://archive.ics.uci.edu/ml/datasets/wine\">https://archive.ics.uci.edu/ml/datasets/wine</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210757_1005021760","id":"20190611-123710_1870998178","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17695"},{"text":"// Load and parse the data\nval data = spark.read.format(\"csv\").option(\"header\", \"false\").load(HdfsUrl + dataRepo)","user":"anonymous","dateUpdated":"2019-06-13T13:35:37+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"data: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 12 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=107"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1560422210757_551848526","id":"20190611-124117_1509176682","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:35:37+0000","dateFinished":"2019-06-13T13:35:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17696"},{"text":"data.count()","user":"anonymous","dateUpdated":"2019-06-13T13:32:08+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res2: Long = 130\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=1"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1560422210757_-379830622","id":"20190612-074817_885713612","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:32:08+0000","dateFinished":"2019-06-13T13:32:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17697"},{"text":"data.take(2).foreach(println)","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1,14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065]\n[1,13.2,1.78,2.14,11.2,100,2.65,2.76,.26,1.28,4.38,1.05,3.4,1050]\n"}]},"apps":[],"jobName":"paragraph_1560422210758_-286168037","id":"20190612-084457_222134128","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17698"},{"text":"%md\nWe have first value corresponding to class of wine and others are explicatives variables","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We have first value corresponding to class of wine and others are explicatives variables</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210758_1593797829","id":"20190612-084511_403147717","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17699"},{"text":"%md\n# Transform data\nWe need to transform data to format that is needed for modelling in mllib.\n\nTo know the input needed for each model, we can see examples in https://spark.apache.org/docs/latest/mllib-linear-methods.html#classification for our example. Here, we need a RDD[LabeledPoint]","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Transform data</h1>\n<p>We need to transform data to format that is needed for modelling in mllib.</p>\n<p>To know the input needed for each model, we can see examples in <a href=\"https://spark.apache.org/docs/latest/mllib-linear-methods.html#classification\">https://spark.apache.org/docs/latest/mllib-linear-methods.html#classification</a> for our example. Here, we need a RDD[LabeledPoint]</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210758_1464491769","id":"20190611-124400_1072583055","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17700"},{"text":"// convert to rdd (because we need it to create a mllib model)\r\nval data_modified = data.map(l => (l(0).asInstanceOf[String].toDouble, l(1).asInstanceOf[String].toDouble, \r\n                                l(2).asInstanceOf[String].toDouble, l(3).asInstanceOf[String].toDouble,\r\n                                l(4).asInstanceOf[String].toDouble, l(5).asInstanceOf[String].toDouble, \r\n                                l(6).asInstanceOf[String].toDouble, l(7).asInstanceOf[String].toDouble,\r\n                                l(8).asInstanceOf[String].toDouble, l(9).asInstanceOf[String].toDouble, \r\n                                l(10).asInstanceOf[String].toDouble, l(11).asInstanceOf[String].toDouble,\r\n                                l(12).asInstanceOf[String].toDouble, l(13).asInstanceOf[String].toDouble)).rdd\r\n                                // change class 2 into class 0 (because in classification in Spark, it understands the label only when it starts by 0, 1, .., n)\r\n                                .map(l => (if (l._1 == 2.0) 0.0 else l._1, l._2,\r\n                                            l._3, l._4, l._5, l._6, l._7, l._8, l._9,\r\n                                             l._10, l._11, l._12, l._13, l._14))","user":"anonymous","dateUpdated":"2019-06-13T13:35:40+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"data_modified: org.apache.spark.rdd.RDD[(Double, Double, Double, Double, Double, Double, Double, Double, Double, Double, Double, Double, Double, Double)] = MapPartitionsRDD[239] at map at <console>:55\n"}]},"apps":[],"jobName":"paragraph_1560422210758_-1062543904","id":"20190611-123644_1209997028","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:35:40+0000","dateFinished":"2019-06-13T13:35:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17701"},{"text":"// Convert to format RDD[LabeledPoint]\nval parsedData = data_modified.map(l => (LabeledPoint(l._1, Vectors.dense(l._2, l._3, l._4, l._5, l._6, l._7, l._8, l._9,\n                                                                            l._10, l._11, l._12, l._13, l._14))))","user":"anonymous","dateUpdated":"2019-06-13T13:35:42+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"parsedData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[240] at map at <console>:49\n"}]},"apps":[],"jobName":"paragraph_1560422210759_893899447","id":"20190612-082630_359546922","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:35:42+0000","dateFinished":"2019-06-13T13:35:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17702"},{"text":"parsedData.take(10)","user":"anonymous","dateUpdated":"2019-06-13T13:35:52+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res6: Array[org.apache.spark.mllib.regression.LabeledPoint] = Array((1.0,[14.23,1.71,2.43,15.6,127.0,2.8,3.06,0.28,2.29,5.64,1.04,3.92,1065.0]), (1.0,[13.2,1.78,2.14,11.2,100.0,2.65,2.76,0.26,1.28,4.38,1.05,3.4,1050.0]), (1.0,[13.16,2.36,2.67,18.6,101.0,2.8,3.24,0.3,2.81,5.68,1.03,3.17,1185.0]), (1.0,[14.37,1.95,2.5,16.8,113.0,3.85,3.49,0.24,2.18,7.8,0.86,3.45,1480.0]), (1.0,[13.24,2.59,2.87,21.0,118.0,2.8,2.69,0.39,1.82,4.32,1.04,2.93,735.0]), (1.0,[14.2,1.76,2.45,15.2,112.0,3.27,3.39,0.34,1.97,6.75,1.05,2.85,1450.0]), (1.0,[14.39,1.87,2.45,14.6,96.0,2.5,2.52,0.3,1.98,5.25,1.02,3.58,1290.0]), (1.0,[14.06,2.15,2.61,17.6,121.0,2.6,2.51,0.31,1.25,5.05,1.06,3.58,1295.0]), (1.0,[14.83,1.64,2.17,14.0,97.0,2.8,2.98,0.29,1.98,5.2,1.08,2.85,1045.0]), (1.0,[13.86,1.35,2.27,16.0,98.0,2.98,3.15,0...."}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=109"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1560422210759_1939766974","id":"20190611-133048_753971650","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:35:52+0000","dateFinished":"2019-06-13T13:35:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17703"},{"text":"%md\n# Divide data into train and test set\n\nWe divide parsedData into train and test set","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Divide data into train and test set</h1>\n<p>We divide parsedData into train and test set</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210759_-669808162","id":"20190612-072532_1404481235","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17704"},{"text":"// Split en train and test set\r\nval Array(trainData, testData) = parsedData.randomSplit(Array(0.7, 0.3))\r\n\r\n// Number of data in train and test set\r\nval numTrain = trainData.count()\r\nval numTest = testData.count()","user":"anonymous","dateUpdated":"2019-06-13T13:35:55+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"trainData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[241] at randomSplit at <console>:54\ntestData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[242] at randomSplit at <console>:54\nnumTrain: Long = 102\nnumTest: Long = 28\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=110","http://172.17.0.2:4040/jobs/job?id=111"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1560422210759_1917926421","id":"20190612-072912_587373246","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:35:55+0000","dateFinished":"2019-06-13T13:35:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17705"},{"text":"%md\n# Build model","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Build model</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210760_1893532826","id":"20190611-133059_1612258304","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17706"},{"text":"// Building the model\nval numIterations = 100\nval model = SVMWithSGD.train(trainData, numIterations)","user":"anonymous","dateUpdated":"2019-06-13T13:35:58+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"numIterations: Int = 100\nmodel: org.apache.spark.mllib.classification.SVMModel = org.apache.spark.mllib.classification.SVMModel: intercept = 0.0, numFeatures = 13, numClasses = 2, threshold = 0.0\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.2:4040/jobs/job?id=112","http://172.17.0.2:4040/jobs/job?id=113","http://172.17.0.2:4040/jobs/job?id=114","http://172.17.0.2:4040/jobs/job?id=115","http://172.17.0.2:4040/jobs/job?id=116","http://172.17.0.2:4040/jobs/job?id=117","http://172.17.0.2:4040/jobs/job?id=118","http://172.17.0.2:4040/jobs/job?id=119","http://172.17.0.2:4040/jobs/job?id=120","http://172.17.0.2:4040/jobs/job?id=121","http://172.17.0.2:4040/jobs/job?id=122","http://172.17.0.2:4040/jobs/job?id=123","http://172.17.0.2:4040/jobs/job?id=124","http://172.17.0.2:4040/jobs/job?id=125","http://172.17.0.2:4040/jobs/job?id=126","http://172.17.0.2:4040/jobs/job?id=127","http://172.17.0.2:4040/jobs/job?id=128","http://172.17.0.2:4040/jobs/job?id=129","http://172.17.0.2:4040/jobs/job?id=130","http://172.17.0.2:4040/jobs/job?id=131","http://172.17.0.2:4040/jobs/job?id=132","http://172.17.0.2:4040/jobs/job?id=133","http://172.17.0.2:4040/jobs/job?id=134","http://172.17.0.2:4040/jobs/job?id=135","http://172.17.0.2:4040/jobs/job?id=136","http://172.17.0.2:4040/jobs/job?id=137","http://172.17.0.2:4040/jobs/job?id=138","http://172.17.0.2:4040/jobs/job?id=139","http://172.17.0.2:4040/jobs/job?id=140","http://172.17.0.2:4040/jobs/job?id=141","http://172.17.0.2:4040/jobs/job?id=142","http://172.17.0.2:4040/jobs/job?id=143","http://172.17.0.2:4040/jobs/job?id=144","http://172.17.0.2:4040/jobs/job?id=145","http://172.17.0.2:4040/jobs/job?id=146","http://172.17.0.2:4040/jobs/job?id=147","http://172.17.0.2:4040/jobs/job?id=148","http://172.17.0.2:4040/jobs/job?id=149","http://172.17.0.2:4040/jobs/job?id=150","http://172.17.0.2:4040/jobs/job?id=151","http://172.17.0.2:4040/jobs/job?id=152","http://172.17.0.2:4040/jobs/job?id=153","http://172.17.0.2:4040/jobs/job?id=154","http://172.17.0.2:4040/jobs/job?id=155","http://172.17.0.2:4040/jobs/job?id=156","http://172.17.0.2:4040/jobs/job?id=157","http://172.17.0.2:4040/jobs/job?id=158","http://172.17.0.2:4040/jobs/job?id=159","http://172.17.0.2:4040/jobs/job?id=160","http://172.17.0.2:4040/jobs/job?id=161","http://172.17.0.2:4040/jobs/job?id=162","http://172.17.0.2:4040/jobs/job?id=163","http://172.17.0.2:4040/jobs/job?id=164","http://172.17.0.2:4040/jobs/job?id=165","http://172.17.0.2:4040/jobs/job?id=166","http://172.17.0.2:4040/jobs/job?id=167","http://172.17.0.2:4040/jobs/job?id=168","http://172.17.0.2:4040/jobs/job?id=169","http://172.17.0.2:4040/jobs/job?id=170","http://172.17.0.2:4040/jobs/job?id=171","http://172.17.0.2:4040/jobs/job?id=172","http://172.17.0.2:4040/jobs/job?id=173","http://172.17.0.2:4040/jobs/job?id=174","http://172.17.0.2:4040/jobs/job?id=175","http://172.17.0.2:4040/jobs/job?id=176","http://172.17.0.2:4040/jobs/job?id=177","http://172.17.0.2:4040/jobs/job?id=178","http://172.17.0.2:4040/jobs/job?id=179","http://172.17.0.2:4040/jobs/job?id=180","http://172.17.0.2:4040/jobs/job?id=181","http://172.17.0.2:4040/jobs/job?id=182","http://172.17.0.2:4040/jobs/job?id=183","http://172.17.0.2:4040/jobs/job?id=184","http://172.17.0.2:4040/jobs/job?id=185","http://172.17.0.2:4040/jobs/job?id=186","http://172.17.0.2:4040/jobs/job?id=187","http://172.17.0.2:4040/jobs/job?id=188","http://172.17.0.2:4040/jobs/job?id=189","http://172.17.0.2:4040/jobs/job?id=190","http://172.17.0.2:4040/jobs/job?id=191","http://172.17.0.2:4040/jobs/job?id=192","http://172.17.0.2:4040/jobs/job?id=193","http://172.17.0.2:4040/jobs/job?id=194","http://172.17.0.2:4040/jobs/job?id=195","http://172.17.0.2:4040/jobs/job?id=196","http://172.17.0.2:4040/jobs/job?id=197","http://172.17.0.2:4040/jobs/job?id=198","http://172.17.0.2:4040/jobs/job?id=199","http://172.17.0.2:4040/jobs/job?id=200","http://172.17.0.2:4040/jobs/job?id=201","http://172.17.0.2:4040/jobs/job?id=202","http://172.17.0.2:4040/jobs/job?id=203","http://172.17.0.2:4040/jobs/job?id=204","http://172.17.0.2:4040/jobs/job?id=205","http://172.17.0.2:4040/jobs/job?id=206","http://172.17.0.2:4040/jobs/job?id=207","http://172.17.0.2:4040/jobs/job?id=208","http://172.17.0.2:4040/jobs/job?id=209","http://172.17.0.2:4040/jobs/job?id=210","http://172.17.0.2:4040/jobs/job?id=211","http://172.17.0.2:4040/jobs/job?id=212","http://172.17.0.2:4040/jobs/job?id=213","http://172.17.0.2:4040/jobs/job?id=214"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1560422210760_1343608465","id":"20190611-133128_1723137507","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:35:58+0000","dateFinished":"2019-06-13T13:36:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17707"},{"text":"%md\n# Evaluate model","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Evaluate model</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210760_-85733634","id":"20190611-133431_1244482931","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17708"},{"text":"// Compute raw scores on the test set.\r\nval scoreAndLabels = testData.map { point =>\r\n  val score = model.predict(point.features)\r\n  (score, point.label)\r\n}\r\n\r\n// Get evaluation metrics.\r\nval metrics = new BinaryClassificationMetrics(scoreAndLabels)\r\nval auROC = metrics.areaUnderROC()\r\n\r\nprintln(\"Area under ROC = \" + auROC)","user":"anonymous","dateUpdated":"2019-06-13T13:32:31+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.SparkException: Task not serializable\n  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:340)\n  at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:330)\n  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:156)\n  at org.apache.spark.SparkContext.clean(SparkContext.scala:2294)\n  at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:370)\n  at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:369)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.map(RDD.scala:369)\n  ... 51 elided\nCaused by: java.io.NotSerializableException: org.apache.hadoop.fs.Path\nSerialization stack:\n\t- object not serializable (class: org.apache.hadoop.fs.Path, value: hdfs://hupi-factory-02-01-01.factory02.viet.cloud-torus.com:8020/user/factory02/formation_hupi/models/svm_model)\n\t- field (class: $iw, name: savePath, type: class org.apache.hadoop.fs.Path)\n\t- object (class $iw, $iw@2bf8a16a)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@55eacb3)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@4e8e94fb)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@604808c9)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@5823aa6f)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@5b03da47)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@512cf557)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@1539d857)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@24d775dd)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@3e9de5c7)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@cd8053d)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@3844e4dc)\n\t- field (class: $line40227850723.$read, name: $iw, type: class $iw)\n\t- object (class $line40227850723.$read, $line40227850723.$read@6ffb140c)\n\t- field (class: $iw, name: $line40227850723$read, type: class $line40227850723.$read)\n\t- object (class $iw, $iw@fabfb95)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@34a7583d)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@22d8d596)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@28faa3cc)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@4e628f9e)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@7ddcb0eb)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@43252a6a)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@2fabe2cd)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@1c2d50b4)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@29cb72)\n\t- field (class: $iw, name: $iw, type: class $iw)\n\t- object (class $iw, $iw@6c94d24d)\n\t- field (class: $line40227850730.$read, name: $iw, type: class $iw)\n\t- object (class $line40227850730.$read, $line40227850730.$read@55a2cba9)\n\t- field (class: $iw, name: $line40227850730$read, type: class $line40227850730.$read)\n\t- object (class $iw, $iw@fedaf23)\n\t- field (class: $iw, name: $outer, type: class $iw)\n\t- object (class $iw, $iw@7ff5bb45)\n\t- field (class: $anonfun$1, name: $outer, type: class $iw)\n\t- object (class $anonfun$1, <function1>)\n  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40)\n  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)\n  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:337)\n  ... 60 more\n"}]},"apps":[],"jobName":"paragraph_1560422210760_-57683142","id":"20190611-133447_1950033493","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:32:31+0000","dateFinished":"2019-06-13T13:32:31+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:17709"},{"text":"%md\nFor more metrics computation, we can find more in https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.BinaryClassificationMetrics","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>For more metrics computation, we can find more in <a href=\"https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\">https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.BinaryClassificationMetrics</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210761_-1913149900","id":"20190612-084056_790914255","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17710"},{"text":"//metrics.fMeasureByThreshold().take(10)\n//metrics.precisionByThreshold().take(10)\n//metrics.recallByThreshold().take(10)","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res12: Array[(Double, Double)] = Array((1.0,0.8717948717948718), (0.0,0.6461538461538462))\n"}]},"apps":[],"jobName":"paragraph_1560422210761_-1302800044","id":"20190612-083923_202183067","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17711"},{"text":"%md\n# Save and load model\n\nHere, we can save model in server and reload it ","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Save and load model</h1>\n<p>Here, we can save model in server and reload it</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210761_2024952848","id":"20190611-134026_895879903","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17712"},{"text":"// Save and load model\r\nmodel.save(sc, saveAddress)\r\n// val sameModel = SVMModel.load(sc, \"target/tmp/scalaSVMWithSGDModel\")","user":"anonymous","dateUpdated":"2019-06-13T13:40:31+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560422210761_-1152133247","id":"20190611-133416_76587478","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17713"},{"text":"%md\n# Convert to PMML Model\n\nWe can convert this model to PMML format. Then, we only need to copy the PMML part and paste it to Hupi-Front to create API predict","user":"anonymous","dateUpdated":"2019-06-13T10:36:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Convert to PMML Model</h1>\n<p>We can convert this model to PMML format. Then, we only need to copy the PMML part and paste it to Hupi-Front to create API predict</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1560422210762_-1768997166","id":"20190612-085040_1152191010","dateCreated":"2019-06-13T10:36:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:17714"},{"text":"print(model.toPMML)","user":"anonymous","dateUpdated":"2019-06-13T13:39:36+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<PMML version=\"4.2\" xmlns=\"http://www.dmg.org/PMML-4_2\">\n    <Header description=\"linear SVM\">\n        <Application name=\"Apache Spark MLlib\" version=\"0.8.1\"/>\n        <Timestamp>2019-06-13T13:39:36</Timestamp>\n    </Header>\n    <DataDictionary numberOfFields=\"14\">\n        <DataField name=\"field_0\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_1\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_2\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_3\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_4\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_5\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_6\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_7\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_8\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_9\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_10\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_11\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"field_12\" optype=\"continuous\" dataType=\"double\"/>\n        <DataField name=\"target\" optype=\"categorical\" dataType=\"string\"/>\n    </DataDictionary>\n    <RegressionModel modelName=\"linear SVM\" functionName=\"classification\" normalizationMethod=\"none\">\n        <MiningSchema>\n            <MiningField name=\"field_0\" usageType=\"active\"/>\n            <MiningField name=\"field_1\" usageType=\"active\"/>\n            <MiningField name=\"field_2\" usageType=\"active\"/>\n            <MiningField name=\"field_3\" usageType=\"active\"/>\n            <MiningField name=\"field_4\" usageType=\"active\"/>\n            <MiningField name=\"field_5\" usageType=\"active\"/>\n            <MiningField name=\"field_6\" usageType=\"active\"/>\n            <MiningField name=\"field_7\" usageType=\"active\"/>\n            <MiningField name=\"field_8\" usageType=\"active\"/>\n            <MiningField name=\"field_9\" usageType=\"active\"/>\n            <MiningField name=\"field_10\" usageType=\"active\"/>\n            <MiningField name=\"field_11\" usageType=\"active\"/>\n            <MiningField name=\"field_12\" usageType=\"active\"/>\n            <MiningField name=\"target\" usageType=\"target\"/>\n        </MiningSchema>\n        <RegressionTable intercept=\"0.0\" targetCategory=\"1\">\n            <NumericPredictor name=\"field_0\" coefficient=\"-25.74653204464602\"/>\n            <NumericPredictor name=\"field_1\" coefficient=\"-4.041320273098033\"/>\n            <NumericPredictor name=\"field_2\" coefficient=\"-4.923039161471247\"/>\n            <NumericPredictor name=\"field_3\" coefficient=\"-57.878967265455046\"/>\n            <NumericPredictor name=\"field_4\" coefficient=\"-195.58616679861495\"/>\n            <NumericPredictor name=\"field_5\" coefficient=\"-3.7582753046049615\"/>\n            <NumericPredictor name=\"field_6\" coefficient=\"-2.4975389255788087\"/>\n            <NumericPredictor name=\"field_7\" coefficient=\"-1.0201441254331265\"/>\n            <NumericPredictor name=\"field_8\" coefficient=\"-3.2355137765481214\"/>\n            <NumericPredictor name=\"field_9\" coefficient=\"-1.2804252463507868\"/>\n            <NumericPredictor name=\"field_10\" coefficient=\"-2.5700683000088493\"/>\n            <NumericPredictor name=\"field_11\" coefficient=\"-5.611050447446918\"/>\n            <NumericPredictor name=\"field_12\" coefficient=\"27.33742208636777\"/>\n        </RegressionTable>\n        <RegressionTable intercept=\"0.0\" targetCategory=\"0\"/>\n    </RegressionModel>\n</PMML>\n"}]},"apps":[],"jobName":"paragraph_1560422210762_-1147388878","id":"20190612-085205_400795191","dateCreated":"2019-06-13T10:36:50+0000","dateStarted":"2019-06-13T13:39:36+0000","dateFinished":"2019-06-13T13:39:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17715"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1560433176780_-1134572930","id":"20190613-133936_388514160","dateCreated":"2019-06-13T13:39:36+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:17716"}],"name":"MONTUS/Formation - 2 Modelling Scala (SVM classification)","id":"2EE4PS13J","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}