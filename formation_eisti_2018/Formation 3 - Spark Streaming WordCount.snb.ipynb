{"metadata":{"id":"164851bf-b5a6-4fc0-9979-ab6768a0470b","name":"Formation 3 - Spark Streaming WordCount.snb.ipynb","user_save_timestamp":"2018-11-19T10:15:25.975Z","auto_save_timestamp":"1970-01-01T00:00:00.000Z","language_info":{"name":"scala","file_extension":"scala","codemirror_mode":"text/x-scala"},"trusted":true,"sparkNotebook":null,"customLocalRepo":null,"customRepos":null,"customDeps":["org.apache.spark % spark-streaming-kafka-0-8_2.11 % 2.1.1"],"customImports":null,"customArgs":null,"customSparkConf":null,"customVars":null},"cells":[{"metadata":{"id":"A47A0BCADB5B468E8A3C71B74CB86E2A"},"cell_type":"markdown","source":"### Spark Streaming\n\nSpark Streaming is an extension of the core Spark API that enables scalable, high-throughput, \nfault-tolerant stream processing of live data streams. Data can be ingested from many sources like \nKafka, Flume, Kinesis, or TCP sockets, and can be processed using complex algorithms expressed \nwith high-level functions like map, reduce, join and window. Finally, processed data can be \npushed out to filesystems, databases, and live dashboards. In fact, you can apply Sparkâ€™s machine learning and graph processing algorithms on data streams."},{"metadata":{"id":"C5CFCAAC9A21424A83EB2A2A45EE3BF2"},"cell_type":"markdown","source":"First, we import the names of the Spark Streaming classes and some implicit conversions from StreamingContext into our environment in order to add useful methods to other classes we need (like DStream). StreamingContext is the main entry point for all streaming functionality. We create a local StreamingContext with two execution threads, and a batch interval of 1 second.\n\nhttps://spark.apache.org/docs/2.2.0/streaming-programming-guide.html\n\nhttps://acadgild.com/blog/spark-streaming-kafka-integration"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"C9BB1D25CB1946838F4A2067B4187257"},"cell_type":"code","source":["import org.apache.spark.streaming._\n","import org.apache.spark.streaming.StreamingContext._\n","import org.apache.spark.SparkConf\n","import org.apache.spark.streaming.kafka._"],"outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.streaming._\nimport org.apache.spark.streaming.StreamingContext._\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming.kafka._\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":1,"time":"Took: 1.390s, at 2018-11-19 09:23"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"A8C0CE835D564BF686EDBFB0F10CA91E"},"cell_type":"code","source":["// Create a local StreamingContext with two working thread and batch interval of 1 second.\n","val conf = new SparkConf().setMaster(\"local[2]\").setAppName(\"NetworkWordCount\")\n","val ssc =  new StreamingContext(sparkContext, Seconds(1))"],"outputs":[{"name":"stdout","output_type":"stream","text":"conf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@54ad35ba\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@7c6300ff\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":2,"time":"Took: 1.203s, at 2018-11-19 09:23"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"5160A75D5F0248FBA805F40479D9CF52"},"cell_type":"code","source":["val zkQuorum = \"hupi-factory-02-02-05-01:2181\"\n","val group = \"DEMO_HUPI_VINCENT\"\n","val topics = \"factory02_test123\"\n","val numThreads = \"1\""],"outputs":[{"name":"stdout","output_type":"stream","text":"zkQuorum: String = hupi-factory-02-02-05-01:2181\ngroup: String = DEMO_HUPI_VINCENT\ntopics: String = factory02_test123\nnumThreads: String = 1\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":3,"time":"Took: 1.015s, at 2018-11-19 09:23"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"19A5D3B11D804F968706FB8B7775E7F9"},"cell_type":"code","source":["// Print What is read from Kafka code\n","val topicMap = topics.split(\",\").map((_, numThreads.toInt)).toMap\n","val streamdata = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap)\n"],"outputs":[{"name":"stdout","output_type":"stream","text":"topicMap: scala.collection.immutable.Map[String,Int] = Map(factory02_test123 -> 1)\nstreamdata: org.apache.spark.streaming.dstream.ReceiverInputDStream[(String, String)] = org.apache.spark.streaming.kafka.KafkaInputDStream@38dfaf19\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":4,"time":"Took: 1.648s, at 2018-11-19 09:23"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"B656A7210BF3422194578E8C0BBCBE2F"},"cell_type":"code","source":["streamdata.foreachRDD {\n","  rdd => {\n","    val words = rdd.flatMap(x =>  x._2.split(\" \"))\n","    val wordCounts = words.map(x => (x, 1)).reduceByKey(_ + _)\n","    rdd.collect().foreach(println) //prints the stream of data received\n","    wordCounts.collect().foreach(println)  //prints the wordcount result of the stream\n","  }\n","}"],"outputs":[{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":5,"time":"Took: 1.731s, at 2018-11-19 09:23"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"E86FAFF5524F4DE48CD4B188C6E5C981"},"cell_type":"code","source":["// Start the computation\n","ssc.start()"],"outputs":[{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":6,"time":"Took: 1.802s, at 2018-11-19 09:23"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"1982B9D867AF4342BFA2B3CA7FE0280C"},"cell_type":"code","source":["ssc.stop(stopSparkContext =true, stopGracefully = true)\n","ssc.awaitTermination()"],"outputs":[{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":7,"time":"Took: 3.104s, at 2018-11-19 09:23"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"06021F9346FC4BDC955171918802544F"},"cell_type":"code","source":[""],"outputs":[]}],"nbformat":4}