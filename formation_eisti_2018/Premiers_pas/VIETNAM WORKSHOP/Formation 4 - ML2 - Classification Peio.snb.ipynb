{
  "metadata" : {
    "id" : "f368205b-4bdf-491b-b953-93ace39f3557",
    "name" : "Formation 4 - ML2 - Classification Peio",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "id" : "FB01318FA4A440BFAA6FCFD46FC49C81"
      },
      "cell_type" : "markdown",
      "source" : "<img src=http://fd.perso.eisti.fr/Logos/TORUS2.png>"
    },
    {
      "metadata" : {
        "id" : "5F687656ADF14F5B95AA9F6C8DF0035D"
      },
      "cell_type" : "markdown",
      "source" : "To illustrate classification algorithms, an example of Random Forest will be enough!\n\n\"Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set\"\n\n(source : https://en.wikipedia.org/wiki/Random_forest)"
    },
    {
      "metadata" : {
        "id" : "69E1DBB6815249F695137621B1D60C2B"
      },
      "cell_type" : "markdown",
      "source" : "### Read dataset (csv format) from HDFS\n\nHere we use the dataset from https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival\n\nThe target variable will be Survival status (1 - the patient survived 5 years or longer and 2 - the patient died within 5 year ) and the variables descriptives are : \n- Age of patient at time of operation (numerical) \n- Patient's year of operation (year - 1900, numerical) \n- Number of positive axillary nodes detected (numerical) "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab1599598013-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "7D20B9182CD34E1887E1AC69C21C695D"
      },
      "cell_type" : "code",
      "source" : [
        "val sqlContext = new SQLContext(sc)\n",
        "\n",
        "val data = sqlContext.read.format(\"com.databricks.spark.csv\")\n",
        "              .option(\"header\", \"true\").option(\"inferSchema\", \"true\") \n",
        "              .load(\"hdfs://hupi-factory-02-01-01-01/user/hupi/dataset_torusVN/formation4_ML/haberman.csv\")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:71: warning: constructor SQLContext in class SQLContext is deprecated: Use SparkSession.builder instead\n       val sqlContext = new SQLContext(sc)\n                        ^\nsqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@5e3be9c6\ndata: org.apache.spark.sql.DataFrame = [age: int, nbYearOperation: int ... 2 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 1,
          "time" : "Took: 1.025s, at 2017-09-06 10:00"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab1154730564-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "4350A09EB48640BA805CB74960005A05"
      },
      "cell_type" : "code",
      "source" : [
        "data.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+---+---------------+-------------+------+\n|age|nbYearOperation|nbPosAxillary|status|\n+---+---------------+-------------+------+\n| 30|             64|            1|     1|\n| 30|             62|            3|     1|\n| 30|             65|            0|     1|\n| 31|             59|            2|     1|\n| 31|             65|            4|     1|\n| 33|             58|           10|     1|\n| 33|             60|            0|     1|\n| 34|             59|            0|     2|\n| 34|             66|            9|     2|\n| 34|             58|           30|     1|\n| 34|             60|            1|     1|\n| 34|             61|           10|     1|\n| 34|             67|            7|     1|\n| 34|             60|            0|     1|\n| 35|             64|           13|     1|\n| 35|             63|            0|     1|\n| 36|             60|            1|     1|\n| 36|             69|            0|     1|\n| 37|             60|            0|     1|\n| 37|             63|            0|     1|\n+---+---------------+-------------+------+\nonly showing top 20 rows\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 2,
          "time" : "Took: 1.872s, at 2017-08-30 12:59"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "F39A4D6BC9E84F45AB75742A2C87F296"
      },
      "cell_type" : "code",
      "source" : [
        "// Convert to RDD and replace status 2 by 0 because the format needed for input of model is 2 values : 0 and 1. Then we should create a rdd of labeledPoint\n",
        "\n",
        "import org.apache.spark.mllib.linalg.Vectors\n",
        "import org.apache.spark.mllib.regression.LabeledPoint\n",
        "\n",
        "val data_rdd = data.map(l => (l(3).asInstanceOf[Int].toString.replace(\"2\", \"0\").toDouble, l(1).asInstanceOf[Int].toDouble, \n",
        "                             l(2).asInstanceOf[Int].toDouble, l(0).asInstanceOf[Int].toDouble)).map(l => LabeledPoint(l._1, Vectors.dense(l._2, l._3, l._4))).rdd"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.regression.LabeledPoint\ndata_rdd: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[25] at rdd at <console>:78\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 2,
          "time" : "Took: 1.088s, at 2017-09-06 10:00"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab1613237694-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "F3A5364748A446F48D982165382927F8"
      },
      "cell_type" : "code",
      "source" : [
        "data_rdd.take(50)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "16A7670AF681478C84C3457C5B79FFA0"
      },
      "cell_type" : "markdown",
      "source" : "### Split randomly data_withGoodColumns to have trainData and testData "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "32EA9C134FAF44D18B70744DEB22A561"
      },
      "cell_type" : "code",
      "source" : [
        "val Array(trainingData, testData) = data_rdd.randomSplit(Array(0.7, 0.3))"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "trainingData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[26] at randomSplit at <console>:76\ntestData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[27] at randomSplit at <console>:76\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 3,
          "time" : "Took: 0.997s, at 2017-09-06 10:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "394ED2D646624DA79B3936C16F94A809"
      },
      "cell_type" : "markdown",
      "source" : "### Build a random forest model "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "E305D86AF212465C88BDFF8B23175D95"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.mllib.tree.RandomForest\n",
        "import org.apache.spark.mllib.tree.model.RandomForestModel\n",
        "\n",
        "val numClasses = 2\n",
        "val categoricalFeaturesInfo = Map[Int, Int]()\n",
        "val numTrees = 10\n",
        "val featureSubsetStrategy = \"auto\" // Let the algorithm choose.\n",
        "val impurity = \"gini\"\n",
        "val maxDepth = 4\n",
        "val maxBins = 32\n",
        "\n",
        "val model = RandomForest.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n",
        "  numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.mllib.tree.RandomForest\nimport org.apache.spark.mllib.tree.model.RandomForestModel\nnumClasses: Int = 2\ncategoricalFeaturesInfo: scala.collection.immutable.Map[Int,Int] = Map()\nnumTrees: Int = 10\nfeatureSubsetStrategy: String = auto\nimpurity: String = gini\nmaxDepth: Int = 4\nmaxBins: Int = 32\nmodel: org.apache.spark.mllib.tree.model.RandomForestModel =\nTreeEnsembleModel classifier with 10 trees\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 4,
          "time" : "Took: 1.985s, at 2017-09-06 10:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "5DAB8E2EDCFF4A80A8A4DDC0C03074A4"
      },
      "cell_type" : "markdown",
      "source" : "### Evaluation of model "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "64614EC412164C5191C232908B63E699"
      },
      "cell_type" : "code",
      "source" : [
        "// Evaluate model on test instances and compute test error\n",
        "val labelAndPreds = testData.map { point =>\n",
        "  val prediction = model.predict(point.features)\n",
        "  (point.label, prediction)\n",
        "}\n",
        "val testErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / testData.count()\n",
        "println(\"Test Error = \" + testErr)\n",
        "println(\"Learned classification forest model:\\n\" + model.toDebugString)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "Test Error = 0.25609756097560976\nLearned classification forest model:\nTreeEnsembleModel classifier with 10 trees\n\n  Tree 0:\n    If (feature 1 <= 8.0)\n     If (feature 1 <= 4.0)\n      If (feature 0 <= 68.0)\n       If (feature 2 <= 65.0)\n        Predict: 1.0\n       Else (feature 2 > 65.0)\n        Predict: 1.0\n      Else (feature 0 > 68.0)\n       If (feature 1 <= 0.0)\n        Predict: 1.0\n       Else (feature 1 > 0.0)\n        Predict: 0.0\n     Else (feature 1 > 4.0)\n      If (feature 0 <= 61.0)\n       Predict: 1.0\n      Else (feature 0 > 61.0)\n       If (feature 2 <= 41.0)\n        Predict: 1.0\n       Else (feature 2 > 41.0)\n        Predict: 0.0\n    Else (feature 1 > 8.0)\n     If (feature 2 <= 45.0)\n      If (feature 0 <= 58.0)\n       Predict: 0.0\n      Else (feature 0 > 58.0)\n       If (feature 2 <= 34.0)\n        Predict: 0.0\n       Else (feature 2 > 34.0)\n        Predict: 1.0\n     Else (feature 2 > 45.0)\n      If (feature 0 <= 65.0)\n       If (feature 2 <= 53.0)\n        Predict: 0.0\n       Else (feature 2 > 53.0)\n        Predict: 0.0\n      Else (feature 0 > 65.0)\n       Predict: 1.0\n  Tree 1:\n    If (feature 2 <= 56.0)\n     If (feature 1 <= 8.0)\n      If (feature 0 <= 63.0)\n       If (feature 2 <= 34.0)\n        Predict: 0.0\n       Else (feature 2 > 34.0)\n        Predict: 1.0\n      Else (feature 0 > 63.0)\n       If (feature 2 <= 40.0)\n        Predict: 1.0\n       Else (feature 2 > 40.0)\n        Predict: 0.0\n     Else (feature 1 > 8.0)\n      If (feature 2 <= 45.0)\n       If (feature 1 <= 16.0)\n        Predict: 1.0\n       Else (feature 1 > 16.0)\n        Predict: 0.0\n      Else (feature 2 > 45.0)\n       If (feature 0 <= 65.0)\n        Predict: 0.0\n       Else (feature 0 > 65.0)\n        Predict: 0.0\n    Else (feature 2 > 56.0)\n     If (feature 0 <= 62.0)\n      If (feature 0 <= 61.0)\n       If (feature 2 <= 65.0)\n        Predict: 1.0\n       Else (feature 2 > 65.0)\n        Predict: 1.0\n      Else (feature 0 > 61.0)\n       If (feature 2 <= 65.0)\n        Predict: 0.0\n       Else (feature 2 > 65.0)\n        Predict: 1.0\n     Else (feature 0 > 62.0)\n      If (feature 0 <= 65.0)\n       If (feature 2 <= 60.0)\n        Predict: 1.0\n       Else (feature 2 > 60.0)\n        Predict: 1.0\n      Else (feature 0 > 65.0)\n       If (feature 1 <= 3.0)\n        Predict: 1.0\n       Else (feature 1 > 3.0)\n        Predict: 1.0\n  Tree 2:\n    If (feature 1 <= 19.0)\n     If (feature 2 <= 38.0)\n      Predict: 1.0\n     Else (feature 2 > 38.0)\n      If (feature 0 <= 58.0)\n       If (feature 1 <= 3.0)\n        Predict: 1.0\n       Else (feature 1 > 3.0)\n        Predict: 0.0\n      Else (feature 0 > 58.0)\n       If (feature 0 <= 64.0)\n        Predict: 1.0\n       Else (feature 0 > 64.0)\n        Predict: 1.0\n    Else (feature 1 > 19.0)\n     If (feature 0 <= 61.0)\n      If (feature 2 <= 43.0)\n       Predict: 0.0\n      Else (feature 2 > 43.0)\n       Predict: 1.0\n     Else (feature 0 > 61.0)\n      Predict: 0.0\n  Tree 3:\n    If (feature 1 <= 9.0)\n     If (feature 1 <= 4.0)\n      If (feature 0 <= 59.0)\n       If (feature 2 <= 34.0)\n        Predict: 0.0\n       Else (feature 2 > 34.0)\n        Predict: 1.0\n      Else (feature 0 > 59.0)\n       If (feature 2 <= 47.0)\n        Predict: 1.0\n       Else (feature 2 > 47.0)\n        Predict: 1.0\n     Else (feature 1 > 4.0)\n      If (feature 1 <= 6.0)\n       If (feature 2 <= 52.0)\n        Predict: 1.0\n       Else (feature 2 > 52.0)\n        Predict: 0.0\n      Else (feature 1 > 6.0)\n       If (feature 2 <= 34.0)\n        Predict: 0.0\n       Else (feature 2 > 34.0)\n        Predict: 1.0\n    Else (feature 1 > 9.0)\n     If (feature 2 <= 38.0)\n      Predict: 1.0\n     Else (feature 2 > 38.0)\n      If (feature 1 <= 24.0)\n       If (feature 2 <= 45.0)\n        Predict: 1.0\n       Else (feature 2 > 45.0)\n        Predict: 0.0\n      Else (feature 1 > 24.0)\n       If (feature 2 <= 43.0)\n        Predict: 0.0\n       Else (feature 2 > 43.0)\n        Predict: 1.0\n  Tree 4:\n    If (feature 1 <= 10.0)\n     If (feature 1 <= 0.0)\n      If (feature 2 <= 40.0)\n       Predict: 1.0\n      Else (feature 2 > 40.0)\n       If (feature 2 <= 49.0)\n        Predict: 1.0\n       Else (feature 2 > 49.0)\n        Predict: 1.0\n     Else (feature 1 > 0.0)\n      If (feature 0 <= 60.0)\n       If (feature 1 <= 3.0)\n        Predict: 1.0\n       Else (feature 1 > 3.0)\n        Predict: 0.0\n      Else (feature 0 > 60.0)\n       If (feature 0 <= 67.0)\n        Predict: 1.0\n       Else (feature 0 > 67.0)\n        Predict: 0.0\n    Else (feature 1 > 10.0)\n     If (feature 0 <= 63.0)\n      If (feature 2 <= 45.0)\n       If (feature 1 <= 15.0)\n        Predict: 1.0\n       Else (feature 1 > 15.0)\n        Predict: 0.0\n      Else (feature 2 > 45.0)\n       If (feature 1 <= 24.0)\n        Predict: 0.0\n       Else (feature 1 > 24.0)\n        Predict: 1.0\n     Else (feature 0 > 63.0)\n      If (feature 1 <= 14.0)\n       Predict: 1.0\n      Else (feature 1 > 14.0)\n       If (feature 1 <= 21.0)\n        Predict: 0.0\n       Else (feature 1 > 21.0)\n        Predict: 1.0\n  Tree 5:\n    If (feature 1 <= 8.0)\n     If (feature 1 <= 4.0)\n      If (feature 2 <= 34.0)\n       Predict: 0.0\n      Else (feature 2 > 34.0)\n       If (feature 0 <= 68.0)\n        Predict: 1.0\n       Else (feature 0 > 68.0)\n        Predict: 1.0\n     Else (feature 1 > 4.0)\n      If (feature 0 <= 61.0)\n       Predict: 1.0\n      Else (feature 0 > 61.0)\n       If (feature 2 <= 41.0)\n        Predict: 1.0\n       Else (feature 2 > 41.0)\n        Predict: 0.0\n    Else (feature 1 > 8.0)\n     If (feature 1 <= 24.0)\n      If (feature 2 <= 38.0)\n       If (feature 1 <= 9.0)\n        Predict: 0.0\n       Else (feature 1 > 9.0)\n        Predict: 1.0\n      Else (feature 2 > 38.0)\n       If (feature 2 <= 45.0)\n        Predict: 0.0\n       Else (feature 2 > 45.0)\n        Predict: 0.0\n     Else (feature 1 > 24.0)\n      Predict: 1.0\n  Tree 6:\n    If (feature 1 <= 8.0)\n     If (feature 2 <= 55.0)\n      If (feature 0 <= 61.0)\n       If (feature 1 <= 1.0)\n        Predict: 1.0\n       Else (feature 1 > 1.0)\n        Predict: 1.0\n      Else (feature 0 > 61.0)\n       If (feature 1 <= 5.0)\n        Predict: 1.0\n       Else (feature 1 > 5.0)\n        Predict: 0.0\n     Else (feature 2 > 55.0)\n      If (feature 0 <= 58.0)\n       If (feature 2 <= 67.0)\n        Predict: 1.0\n       Else (feature 2 > 67.0)\n        Predict: 0.0\n      Else (feature 0 > 58.0)\n       If (feature 2 <= 65.0)\n        Predict: 1.0\n       Else (feature 2 > 65.0)\n        Predict: 1.0\n    Else (feature 1 > 8.0)\n     If (feature 0 <= 60.0)\n      Predict: 0.0\n     Else (feature 0 > 60.0)\n      If (feature 1 <= 24.0)\n       If (feature 2 <= 44.0)\n        Predict: 0.0\n       Else (feature 2 > 44.0)\n        Predict: 0.0\n      Else (feature 1 > 24.0)\n       Predict: 1.0\n  Tree 7:\n    If (feature 1 <= 4.0)\n     If (feature 0 <= 59.0)\n      If (feature 1 <= 3.0)\n       If (feature 2 <= 34.0)\n        Predict: 0.0\n       Else (feature 2 > 34.0)\n        Predict: 1.0\n      Else (feature 1 > 3.0)\n       Predict: 0.0\n     Else (feature 0 > 59.0)\n      If (feature 0 <= 63.0)\n       If (feature 2 <= 67.0)\n        Predict: 1.0\n       Else (feature 2 > 67.0)\n        Predict: 1.0\n      Else (feature 0 > 63.0)\n       If (feature 2 <= 42.0)\n        Predict: 0.0\n       Else (feature 2 > 42.0)\n        Predict: 1.0\n    Else (feature 1 > 4.0)\n     If (feature 1 <= 23.0)\n      If (feature 1 <= 8.0)\n       If (feature 1 <= 6.0)\n        Predict: 0.0\n       Else (feature 1 > 6.0)\n        Predict: 1.0\n      Else (feature 1 > 8.0)\n       If (feature 1 <= 13.0)\n        Predict: 0.0\n       Else (feature 1 > 13.0)\n        Predict: 0.0\n     Else (feature 1 > 23.0)\n      Predict: 1.0\n  Tree 8:\n    If (feature 2 <= 44.0)\n     If (feature 1 <= 16.0)\n      If (feature 1 <= 1.0)\n       If (feature 0 <= 63.0)\n        Predict: 1.0\n       Else (feature 0 > 63.0)\n        Predict: 1.0\n      Else (feature 1 > 1.0)\n       If (feature 0 <= 58.0)\n        Predict: 1.0\n       Else (feature 0 > 58.0)\n        Predict: 1.0\n     Else (feature 1 > 16.0)\n      Predict: 0.0\n    Else (feature 2 > 44.0)\n     If (feature 0 <= 65.0)\n      If (feature 2 <= 61.0)\n       If (feature 1 <= 8.0)\n        Predict: 1.0\n       Else (feature 1 > 8.0)\n        Predict: 0.0\n      Else (feature 2 > 61.0)\n       If (feature 1 <= 3.0)\n        Predict: 1.0\n       Else (feature 1 > 3.0)\n        Predict: 0.0\n     Else (feature 0 > 65.0)\n      If (feature 1 <= 2.0)\n       If (feature 0 <= 67.0)\n        Predict: 1.0\n       Else (feature 0 > 67.0)\n        Predict: 1.0\n      Else (feature 1 > 2.0)\n       If (feature 1 <= 8.0)\n        Predict: 0.0\n       Else (feature 1 > 8.0)\n        Predict: 1.0\n  Tree 9:\n    If (feature 1 <= 10.0)\n     If (feature 0 <= 62.0)\n      If (feature 2 <= 63.0)\n       If (feature 1 <= 2.0)\n        Predict: 1.0\n       Else (feature 1 > 2.0)\n        Predict: 1.0\n      Else (feature 2 > 63.0)\n       If (feature 2 <= 65.0)\n        Predict: 0.0\n       Else (feature 2 > 65.0)\n        Predict: 1.0\n     Else (feature 0 > 62.0)\n      If (feature 1 <= 0.0)\n       If (feature 0 <= 66.0)\n        Predict: 1.0\n       Else (feature 0 > 66.0)\n        Predict: 1.0\n      Else (feature 1 > 0.0)\n       If (feature 2 <= 51.0)\n        Predict: 1.0\n       Else (feature 2 > 51.0)\n        Predict: 0.0\n    Else (feature 1 > 10.0)\n     If (feature 2 <= 43.0)\n      Predict: 1.0\n     Else (feature 2 > 43.0)\n      If (feature 1 <= 22.0)\n       Predict: 0.0\n      Else (feature 1 > 22.0)\n       Predict: 1.0\n\nlabelAndPreds: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[49] at map at <console>:86\ntestErr: Double = 0.25609756097560976\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 5,
          "time" : "Took: 1.422s, at 2017-09-06 10:02"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "7D57476E8F89408FBCFC3C76C9135697"
      },
      "cell_type" : "code",
      "source" : [
        "/*\n",
        "// Save and load model\n",
        "model.save(sc, savePath)\n",
        "val sameModel = RandomForestModel.load(sc, savePath)\n",
        "*/"
      ],
      "outputs" : [ ]
    }
  ],
  "nbformat" : 4
}