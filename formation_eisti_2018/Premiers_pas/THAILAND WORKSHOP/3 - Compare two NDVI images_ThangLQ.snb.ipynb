{
  "metadata" : {
    "id" : "9b87da38-90cf-458a-adfc-444d973e60a3",
    "name" : "3 - Compare two NDVI images_ThangLQ.snb.ipynb",
    "user_save_timestamp" : "2018-02-08T03:47:41.509Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : [
      "osgeo % default % http://download.osgeo.org/webdav/geotools/ % maven"
    ],
    "customDeps" : [
      "org.locationtech.geotrellis % geotrellis-spark_2.11 % 1.2.0"
    ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "id" : "F35652A52FCA4E58A0B31BE98C2132A1"
      },
      "cell_type" : "markdown",
      "source" : "# Import libraries"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "064033D960D846E9880DCE8C4D7EE2C7"
      },
      "cell_type" : "code",
      "source" : [
        "import geotrellis.proj4._\n",
        "\n",
        "import geotrellis.raster._\n",
        "import geotrellis.raster.render._\n",
        "import geotrellis.raster.io.geotiff._\n",
        "import geotrellis.raster.io.geotiff.GeoTiff\n",
        "import geotrellis.raster.io.geotiff.tags.TiffTags\n",
        "import geotrellis.raster.io.geotiff.reader.GeoTiffReader\n",
        "\n",
        "import geotrellis.spark._\n",
        "import geotrellis.spark.io.hadoop._\n",
        "import geotrellis.spark.io.hadoop.formats._\n",
        "import geotrellis.spark.io.RasterReader\n",
        "import geotrellis.spark.tiling.FloatingLayoutScheme\n",
        "\n",
        "import geotrellis.vector._\n",
        "\n",
        "import org.apache.hadoop.conf.Configuration\n",
        "import org.apache.hadoop.fs.Path"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import geotrellis.proj4._\nimport geotrellis.raster._\nimport geotrellis.raster.render._\nimport geotrellis.raster.io.geotiff._\nimport geotrellis.raster.io.geotiff.GeoTiff\nimport geotrellis.raster.io.geotiff.tags.TiffTags\nimport geotrellis.raster.io.geotiff.reader.GeoTiffReader\nimport geotrellis.spark._\nimport geotrellis.spark.io.hadoop._\nimport geotrellis.spark.io.hadoop.formats._\nimport geotrellis.spark.io.RasterReader\nimport geotrellis.spark.tiling.FloatingLayoutScheme\nimport geotrellis.vector._\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.Path\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 1,
          "time" : "Took: 1.792s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "9F9635DCA57145D19711E425804CD9B4"
      },
      "cell_type" : "markdown",
      "source" : "# Important variables"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "44256257F6B748D78FED9E399516350A"
      },
      "cell_type" : "code",
      "source" : [
        "// implicit variable (important variables to run the functions in the geotrellis library)\n",
        "implicit val sparkContext = sc\n",
        "\n",
        "val rr = implicitly[RasterReader[HadoopGeoTiffRDD.Options, (ProjectedExtent, Tile)]]"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "sparkContext: org.apache.spark.SparkContext = org.apache.spark.SparkContext@49dd33f\nrr: geotrellis.spark.io.RasterReader[geotrellis.spark.io.hadoop.HadoopGeoTiffRDD.Options,(geotrellis.vector.ProjectedExtent, geotrellis.raster.Tile)] = geotrellis.spark.io.RasterReader$$anon$1@7083c9de\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 2,
          "time" : "Took: 1.820s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "3CC81605C10148978CED87FB3AAC9F89"
      },
      "cell_type" : "markdown",
      "source" : "# Parameters"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "629CE1563D4A4F6184A410020813CD2A"
      },
      "cell_type" : "code",
      "source" : [
        "val HdfsUrl = \"hdfs://hupi-factory-02-01-01-01/\"\n",
        "val dataRepo = \"user/factory02/thailand_workshop/ndvi/\"\n",
        "val landsatName2017 = \"LC08_L1TP_125052_20171231_20180103_01_T1\"\n",
        "val landsatName2007 = \"LT05_L1GS_125052_20070915_20161112_01_T2\""
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "HdfsUrl: String = hdfs://hupi-factory-02-01-01-01/\ndataRepo: String = user/factory02/thailand_workshop/ndvi/\nlandsatName2017: String = LC08_L1TP_125052_20171231_20180103_01_T1\nlandsatName2007: String = LT05_L1GS_125052_20070915_20161112_01_T2\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 3,
          "time" : "Took: 1.297s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A446F59D4CCE42FF8A67AC528BE4AF5E"
      },
      "cell_type" : "code",
      "source" : [
        "val saveName = HdfsUrl + dataRepo + landsatName2017 + \"VS\" + landsatName2007"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "saveName: String = hdfs://hupi-factory-02-01-01-01/user/factory02/thailand_workshop/ndvi/LC08_L1TP_125052_20171231_20180103_01_T1VSLT05_L1GS_125052_20070915_20161112_01_T2\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 4,
          "time" : "Took: 1.236s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "49A20D686A904485ACF9F4490C3AE250"
      },
      "cell_type" : "markdown",
      "source" : "# To avoid duplicates in HDFS"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "F7CE4B1EC4864EF3831B773DF2395E74"
      },
      "cell_type" : "code",
      "source" : [
        "val conf = sc.hadoopConfiguration  \n",
        "val fs = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(HdfsUrl), conf)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "conf: org.apache.hadoop.conf.Configuration = Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml\nfs: org.apache.hadoop.fs.FileSystem = DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-753263480_11, ugi=root (auth:SIMPLE)]]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 5,
          "time" : "Took: 1.734s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "9B850445BE4A434986185A607BB8C2A8"
      },
      "cell_type" : "code",
      "source" : [
        "// Remove the image png if it's there already\n",
        "fs.delete(new Path(saveName + \".png\"),true)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res6: Boolean = true\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "true"
          },
          "output_type" : "execute_result",
          "execution_count" : 6,
          "time" : "Took: 1.645s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "7B85BE05812C416497F2AB81E957CEC7"
      },
      "cell_type" : "markdown",
      "source" : "# Compare 2 NDVI of 2 images \n\nTo compare 2 NDVI, we compute the difference of NDVI and render to PNG\n\nHere, we will take the NDVI in 2017 and in 2007\n\n#### Firstly, we load NDVI in GeoTiff from HDFS "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "126CBEFB3AB748A4924F76282D44BCCE"
      },
      "cell_type" : "code",
      "source" : [
        "val options =\n",
        "HadoopGeoTiffRDD.Options(\n",
        "  numPartitions = Some(100)\n",
        ")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "options: geotrellis.spark.io.hadoop.HadoopGeoTiffRDD.Options = Options(List(.tif, .TIF, .tiff, .TIFF),None,TIFFTAG_DATETIME,yyyy:MM:dd HH:mm:ss,Some(256),Some(100),Some(134217728),None)\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 7,
          "time" : "Took: 1.165s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "91D1E3891CCA4D6C832D9D55D89CA545"
      },
      "cell_type" : "code",
      "source" : [
        "val ndvi_2017 = HadoopGeoTiffRDD[ProjectedExtent, Tile](\n",
        "      new Path(HdfsUrl + dataRepo + landsatName2017 + \".tif\"), \n",
        "      options).map(l => (l._1, l._2.convert(DoubleConstantNoDataCellType)))\n",
        "\n",
        "val ndvi_2007 = HadoopGeoTiffRDD[ProjectedExtent, Tile](\n",
        "      new Path(HdfsUrl + dataRepo + landsatName2007 + \".tif\"), \n",
        "      options).map(l => (l._1, l._2.convert(DoubleConstantNoDataCellType)))"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "ndvi_2017: org.apache.spark.rdd.RDD[(geotrellis.vector.ProjectedExtent, geotrellis.raster.Tile)] = MapPartitionsRDD[4] at map at <console>:109\nndvi_2007: org.apache.spark.rdd.RDD[(geotrellis.vector.ProjectedExtent, geotrellis.raster.Tile)] = MapPartitionsRDD[9] at map at <console>:113\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 8,
          "time" : "Took: 4.866s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "32BD323E89764EA1969BBF31F8D89AB3"
      },
      "cell_type" : "markdown",
      "source" : "In ndvi_2017, we replace all the negative value to -99. The reason that we need to make the negative value of ndvi 2017 more \"negative\" is if we have -0.5 - (-0.7) = 0.2 => in the output, we may see some strange result..."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "94323E90DA1A43299F87630BB51009C6"
      },
      "cell_type" : "code",
      "source" : [
        "val ndvi_2017_updated = ndvi_2017.map {\n",
        "  case (pe, tile) => {\n",
        "    val arrayTile = tile.toArrayDouble\n",
        "    val newArrayTile = arrayTile.map {\n",
        "      case (value) => {\n",
        "        if (value < 0) \n",
        "        {-99.0} \n",
        "        else {value}\n",
        "      }\n",
        "    }\n",
        "    (pe, DoubleArrayTile(newArrayTile, tile.cols, tile.rows).tile)    \n",
        "  }\n",
        "}"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "ndvi_2017_updated: org.apache.spark.rdd.RDD[(geotrellis.vector.ProjectedExtent, geotrellis.raster.Tile)] = MapPartitionsRDD[10] at map at <console>:108\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 9,
          "time" : "Took: 1.513s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "5FB10251BD0B4817830FC794C1B578A0"
      },
      "cell_type" : "markdown",
      "source" : "#### Then, we convert ProjectedExtent to SpatialKey "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "7BD898C9F4FF49C4AEABB12B847E6E1F"
      },
      "cell_type" : "code",
      "source" : [
        "val (_, metadata_2017) = ndvi_2017_updated.collectMetadata[SpatialKey](FloatingLayoutScheme())\n",
        "val tiles_2017 = ndvi_2017_updated.tileToLayout[SpatialKey](metadata_2017)\n",
        "\n",
        "val (_, metadata_2007) = ndvi_2007.collectMetadata[SpatialKey](FloatingLayoutScheme())\n",
        "val tiles_2007 = ndvi_2007.tileToLayout[SpatialKey](metadata_2007)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "metadata_2017: geotrellis.spark.TileLayerMetadata[geotrellis.spark.SpatialKey] = TileLayerMetadata(float64,GridExtent(Extent(528585.0, 1156335.0, 758985.0, 1394415.0),30.0,30.0),Extent(528585.0, 1156335.0, 758985.0, 1394415.0),EPSG:32648,KeyBounds(SpatialKey(0,0),SpatialKey(29,30)))\ntiles_2017: org.apache.spark.rdd.RDD[(geotrellis.spark.SpatialKey, geotrellis.raster.Tile)] = ShuffledRDD[13] at reduceByKey at TileRDDMerge.scala:51\nmetadata_2007: geotrellis.spark.TileLayerMetadata[geotrellis.spark.SpatialKey] = TileLayerMetadata(float64,GridExtent(Extent(527085.0, 1167075.0, 765165.0, 1382115.0),30.0,30.0),Extent(527085.0, 1167075.0, 765165.0, 1382115.0),EPSG:32648,KeyBounds(SpatialKey(0,0),SpatialKey(30,27)))\ntiles_2007: org.apache.spark.rdd.RDD[(geotrellis.spark.SpatialKey, geotrellis.r..."
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 10,
          "time" : "Took: 20.212s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "BED67906B36B4B2DB7B1CEA48BDE7F81"
      },
      "cell_type" : "markdown",
      "source" : "#### And compute the difference of NDVI"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab364990868-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "A5D41BB1BAE54775A837A79B294C0429"
      },
      "cell_type" : "code",
      "source" : [
        "val difference_ndvi = (tiles_2017 - tiles_2007)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "difference_ndvi: org.apache.spark.rdd.RDD[(geotrellis.spark.SpatialKey, geotrellis.raster.Tile)] = MapPartitionsRDD[20] at mapValues at CombineMethods.scala:32\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 11,
          "time" : "Took: 1.349s, at 2018-01-26 10:05"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "6D393B9AB81B4511B35D34590DB60F14"
      },
      "cell_type" : "markdown",
      "source" : "#### FInally create a raster by stitching all RDD with metadata"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "78659C565B514BBAA6D88D2C2C417D25"
      },
      "cell_type" : "code",
      "source" : [
        "val raster = ContextRDD(difference_ndvi, metadata_2017).stitch"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "raster: geotrellis.raster.Raster[geotrellis.raster.Tile] = Raster(DoubleConstantNoDataArrayTile([D@5ce53313,7680,7168),Extent(528585.0, 1179375.0, 758985.0, 1394415.0))\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 12,
          "time" : "Took: 21.425s, at 2018-01-26 10:06"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "EA24FD27C42C4BD9B3364006BE908661"
      },
      "cell_type" : "markdown",
      "source" : "# By visualization\n\nWe create a PNG of difference_ndvi and save it in HDFS and in server. Here the colorMap, we use < - 2 and make it to blue color (it just means that this is a zone without green in 2007 and 2017). If we see some green in the photo PNG, it means that this zone is greener in 2017 compared to 2007. If it's yellow => it's less green than before.\n\n#### We create the color map"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "3CFE40BABCE84AAEA5C5470133BCBADE"
      },
      "cell_type" : "code",
      "source" : [
        "// NDVI goes from -1 to 1, so <= 0 => ffffe5ff; (0;0.1] : f7fcb9ff, etc.\n",
        "val ndviColormap = \"-2:cc7a00ff;0:ffffe5ff;0.1:f7fcb9ff;0.2:d9f0a3ff;0.3:addd8eff;0.4:78c679ff;0.5:41ab5dff;0.6:238443ff;0.7:006837ff;1:004529ff;2:004529ff\"\n",
        "\n",
        "// Get color map from the application.conf settings file.\n",
        "val colorMap = ColorMap.fromStringDouble(ndviColormap).get"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "ndviColormap: String = -2:cc7a00ff;0:ffffe5ff;0.1:f7fcb9ff;0.2:d9f0a3ff;0.3:addd8eff;0.4:78c679ff;0.5:41ab5dff;0.6:238443ff;0.7:006837ff;1:004529ff;2:004529ff\ncolorMap: geotrellis.raster.render.ColorMap = geotrellis.raster.render.DoubleColorMap@5b0eb0ba\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 23,
          "time" : "Took: 1.167s, at 2018-01-26 10:09"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "D1CD83E1195042BEB41C270CC299F8BB"
      },
      "cell_type" : "markdown",
      "source" : "#### And render tile to PNG with colorMap "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "9F9C67B4B90D4C4C899ECBAA84231425"
      },
      "cell_type" : "code",
      "source" : [
        "val image_png = raster.tile.renderPng(colorMap)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "image_png: geotrellis.raster.render.Png = Png([B@14e768b)\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 24,
          "time" : "Took: 6.081s, at 2018-01-26 10:09"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "CEAF563CD64F42BB972A65FE20A7EC6C"
      },
      "cell_type" : "markdown",
      "source" : "#### Save to HDFS "
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "C879D83380B44A4ABA9A23D12CAFEFA1"
      },
      "cell_type" : "code",
      "source" : [
        "image_png.write(new Path(saveName + \".png\"))"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "No codec found for hdfs://hupi-factory-02-01-01-01/user/factory02/thailand_workshop/ndvi/LC08_L1TP_125052_20171231_20180103_01_T1VSLT05_L1GS_125052_20070915_20161112_01_T2.png, writing without compression.\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 25,
          "time" : "Took: 1.666s, at 2018-01-26 10:09"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A1A504CBA793442A8CF45F9E35C394FB"
      },
      "cell_type" : "markdown",
      "source" : "# Save to server and print image in notebook"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "D37722B914A24DD283915B3ACA827D8A"
      },
      "cell_type" : "code",
      "source" : [
        "val ndviPath_server = \"/opt/docker/notebooks/data/\" + landsatName2017 + \"VS\" + landsatName2007 + \".png\""
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "ndviPath_server: String = /opt/docker/notebooks/data/LC08_L1TP_125052_20171231_20180103_01_T1VSLT05_L1GS_125052_20070915_20161112_01_T2.png\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 26,
          "time" : "Took: 0.911s, at 2018-01-26 10:09"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "FF79C8DC644E40EB8309C061673620C1"
      },
      "cell_type" : "code",
      "source" : [
        "image_png.write(ndviPath_server)"
      ],
      "outputs" : [
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 27,
          "time" : "Took: 1.526s, at 2018-01-26 10:09"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "7FD475C7147846FC9B72FAEF9BB0AE8C"
      },
      "cell_type" : "code",
      "source" : [
        "import java.io.File"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import java.io.File\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 28,
          "time" : "Took: 0.879s, at 2018-01-26 10:09"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "F64F91E6194E49FD91087ABFD3C5E061"
      },
      "cell_type" : "code",
      "source" : [
        "val image_ndvi = img() // default type and size\n",
        "image_ndvi.file(new File(ndviPath_server))"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "image_ndvi: notebook.front.SingleConnectedWidget[java.awt.image.BufferedImage]{implicit val codec: notebook.Codec[play.api.libs.json.JsValue,java.awt.image.BufferedImage]; lazy val toHtml: scala.xml.Elem; def url(u: java.net.URL): Unit; def file(f: java.io.File): Unit} = <$anon$1 widget>\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 29,
          "time" : "Took: 35.278s, at 2018-01-26 10:10"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "F884F6FCA5564F2D8100E1406832A976"
      },
      "cell_type" : "code",
      "source" : [
        "image_ndvi"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res39: notebook.front.SingleConnectedWidget[java.awt.image.BufferedImage]{implicit val codec: notebook.Codec[play.api.libs.json.JsValue,java.awt.image.BufferedImage]; lazy val toHtml: scala.xml.Elem; def url(u: java.net.URL): Unit; def file(f: java.io.File): Unit} = <$anon$1 widget>\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "<p>\n      <img width=\"150px\" height=\"150px\" data-bind=\"attr:{src: value}\"/>\n        <script data-this=\"{&quot;valueId&quot;:&quot;anondf7e5adfc7360ed507894aaf9237b40d&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n            /*]]>*/</script>\n      </p>"
          },
          "output_type" : "execute_result",
          "execution_count" : 30,
          "time" : "Took: 1.258s, at 2018-01-26 10:10"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "F5E99B2699B0498D8E6C1B0C15DF176F"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 31,
          "time" : "Took: 1.218s, at 2018-01-26 10:10"
        }
      ]
    }
  ]
}