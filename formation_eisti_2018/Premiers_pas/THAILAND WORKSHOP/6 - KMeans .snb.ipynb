{
  "metadata" : {
    "id" : "5ba3f865-a7a7-4e93-8e3b-80461814212e",
    "name" : "6 - KMeans ",
    "user_save_timestamp" : "2018-01-08T10:00:53.605Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : [
      "osgeo % default % http://download.osgeo.org/webdav/geotools/ % maven"
    ],
    "customDeps" : [
      "org.locationtech.geotrellis % geotrellis-spark_2.11 % 1.2.0",
      "- org.apache.hadoop % hadoop-client % _",
      "- org.apache.spark % spark-core_2.11 % _",
      "- org.apache.spark % spark-mllib_2.11 % _",
      "- org.apache.spark % spark-repl_2.11 % _",
      "- org.scala-lang % _ % _"
    ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "id" : "832649D1DE8448AB82F3C55B5C2337C7"
      },
      "cell_type" : "markdown",
      "source" : "# Import libraries"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "BEA974C4F20540298704EF6055B877D6"
      },
      "cell_type" : "code",
      "source" : [
        "import geotrellis.raster._\n",
        "import geotrellis.raster.vectorize._\n",
        "import geotrellis.raster.vectorize\n",
        "import geotrellis.raster.io.geotiff._\n",
        "import geotrellis.raster.render._\n",
        "import geotrellis.raster.io.geotiff.GeoTiff\n",
        "import geotrellis.raster.resample._\n",
        "\n",
        "import geotrellis.spark._\n",
        "import geotrellis.spark.io._\n",
        "import geotrellis.spark.io.RasterReader\n",
        "import geotrellis.spark.io.hadoop._\n",
        "import geotrellis.spark.io.hadoop\n",
        "import geotrellis.spark.tiling._\n",
        "import geotrellis.spark.tiling.FloatingLayoutScheme\n",
        "\n",
        "import geotrellis.vector._\n",
        "\n",
        "import org.apache.spark.SparkContext\n",
        "import org.apache.spark.rdd._\n",
        "import org.apache.spark.rdd.RDD\n",
        "import org.apache.spark.HashPartitioner\n",
        "import org.apache.spark.mllib.linalg.{Vector, Vectors}\n",
        "import org.apache.spark.mllib.clustering.{KMeans, KMeansModel}\n",
        "\n",
        "import java.net.URI\n",
        "import scala.math.BigDecimal.RoundingMode\n",
        "import org.apache.hadoop.fs.Path"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import geotrellis.raster._\nimport geotrellis.raster.vectorize._\nimport geotrellis.raster.vectorize\nimport geotrellis.raster.io.geotiff._\nimport geotrellis.raster.render._\nimport geotrellis.raster.io.geotiff.GeoTiff\nimport geotrellis.raster.resample._\nimport geotrellis.spark._\nimport geotrellis.spark.io._\nimport geotrellis.spark.io.RasterReader\nimport geotrellis.spark.io.hadoop._\nimport geotrellis.spark.io.hadoop\nimport geotrellis.spark.tiling._\nimport geotrellis.spark.tiling.FloatingLayoutScheme\nimport geotrellis.vector._\nimport org.apache.spark.SparkContext\nimport org.apache.spark.rdd._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.HashPartitioner\nimport org.apache.spark.mllib.linalg.{Vector, Vectors}\nimport org.apache.spark.mllib.clustering.{KMeans, KMeansModel}\nimport java...."
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 18,
          "time" : "Took: 1.932s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "C4D09E15162E4D8D9D7A35125D7EE82C"
      },
      "cell_type" : "markdown",
      "source" : "# Important variables"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "7FDCF571A0AC47B58DB0A70A18F0BD64"
      },
      "cell_type" : "code",
      "source" : [
        "val rr = implicitly[RasterReader[HadoopGeoTiffRDD.Options, (ProjectedExtent, Tile)]]\n",
        "implicit val sparkContext = sc"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "rr: geotrellis.spark.io.RasterReader[geotrellis.spark.io.hadoop.HadoopGeoTiffRDD.Options,(geotrellis.vector.ProjectedExtent, geotrellis.raster.Tile)] = geotrellis.spark.io.RasterReader$$anon$1@6434d0d5\nsparkContext: org.apache.spark.SparkContext = org.apache.spark.SparkContext@427a7f63\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 3,
          "time" : "Took: 2.063s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "9AF7A48C32A441A981240FCA6AE995B1"
      },
      "cell_type" : "markdown",
      "source" : "# Parameters"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "7DE4DF07A5364D8F9204C6AB33E5C0E0"
      },
      "cell_type" : "code",
      "source" : [
        "val HdfsUrl = \"hdfs://hupi-factory-02-01-01-01/\"\n",
        "val dataRepo = \"user/factory02/thailand_workshop/data_multiBands/\"\n",
        "val saveRepo = \"user/factory02/thailand_workshop/kmeans/\"\n",
        "val landsatName = \"LC08_L1TP_125052_20171231_20180103_01_T1\"\n",
        "val k = 9"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "HdfsUrl: String = hdfs://hupi-factory-02-01-01-01/\ndataRepo: String = user/factory02/thailand_workshop/data_multiBands/\nsaveRepo: String = user/factory02/thailand_workshop/kmeans/\nlandsatName: String = LC08_L1TP_125052_20171231_20180103_01_T1\nk: Int = 9\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 4,
          "time" : "Took: 1.839s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "407635B908C2451D806A3B10FAAEE4FB"
      },
      "cell_type" : "code",
      "source" : [
        "val saveAddress = HdfsUrl + saveRepo + landsatName + \"/\" + k\n",
        "val saveAddressPmml = HdfsUrl + saveRepo + landsatName + \"_PMML\"\n",
        "val savePath = new Path(saveAddress)\n",
        "val savePathPmml = new Path(saveAddressPmml)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "saveAddress: String = hdfs://hupi-factory-02-01-01-01/user/factory02/thailand_workshop/kmeans/LC08_L1TP_125052_20171231_20180103_01_T1/9\nsaveAddressPmml: String = hdfs://hupi-factory-02-01-01-01/user/factory02/thailand_workshop/kmeans/LC08_L1TP_125052_20171231_20180103_01_T1_PMML\nsavePath: org.apache.hadoop.fs.Path = hdfs://hupi-factory-02-01-01-01/user/factory02/thailand_workshop/kmeans/LC08_L1TP_125052_20171231_20180103_01_T1/9\nsavePathPmml: org.apache.hadoop.fs.Path = hdfs://hupi-factory-02-01-01-01/user/factory02/thailand_workshop/kmeans/LC08_L1TP_125052_20171231_20180103_01_T1_PMML\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 5,
          "time" : "Took: 1.971s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "CAA10203FB6848E78B2139818788DDDC"
      },
      "cell_type" : "markdown",
      "source" : "# To avoid duplicates in HDFS"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "E5712D6E322140128AD73739A2E3F486"
      },
      "cell_type" : "code",
      "source" : [
        "val conf = sc.hadoopConfiguration \n",
        "val fs = org.apache.hadoop.fs.FileSystem.get(new java.net.URI(HdfsUrl), conf)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "conf: org.apache.hadoop.conf.Configuration = Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml\nfs: org.apache.hadoop.fs.FileSystem = DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-75799317_11, ugi=root (auth:SIMPLE)]]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 6,
          "time" : "Took: 2.479s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "B10C4B1AD03745CC89A81DFD56291841"
      },
      "cell_type" : "code",
      "source" : [
        "// delete the illustration if it existed already\n",
        "fs.delete(savePath,true)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res7: Boolean = false\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "false"
          },
          "output_type" : "execute_result",
          "execution_count" : 7,
          "time" : "Took: 2.946s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "21E025598845459AB15E3BD586086F3E"
      },
      "cell_type" : "code",
      "source" : [
        "// delete the pmml model if it existed already\n",
        "fs.delete(savePathPmml,true)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res9: Boolean = false\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "false"
          },
          "output_type" : "execute_result",
          "execution_count" : 8,
          "time" : "Took: 2.275s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "CCDED50A968747EC9129BFCD30776FD3"
      },
      "cell_type" : "markdown",
      "source" : "# Load multiBandgeoTiff from HDFS"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "CCCC63CA96254FB2B494F51C02499154"
      },
      "cell_type" : "code",
      "source" : [
        "val options =\n",
        "HadoopGeoTiffRDD.Options(\n",
        "  numPartitions = Some(100)\n",
        ")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "options: geotrellis.spark.io.hadoop.HadoopGeoTiffRDD.Options = Options(List(.tif, .TIF, .tiff, .TIFF),None,TIFFTAG_DATETIME,yyyy:MM:dd HH:mm:ss,Some(256),Some(100),Some(134217728),None)\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 9,
          "time" : "Took: 1.642s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "1C8565EA20B64F07B2E31F6D42F309CD"
      },
      "cell_type" : "code",
      "source" : [
        "// We get multi bands from HDFS (except band 8) \n",
        "val sourceTiles = sc.hadoopMultibandGeoTiffRDD(HdfsUrl + dataRepo + landsatName + \".tif\").repartition(100)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "java.io.IOException: No matching file(s) for path: hdfs://hupi-factory-02-01-01-01/user/factory02/thailand_workshop/data_multiBands/LC08_L1TP_125052_20171231_20180103_01_T1.tif\n  at geotrellis.spark.io.hadoop.HdfsUtils$.listFiles(HdfsUtils.scala:93)\n  at geotrellis.spark.io.hadoop.package$withHadoopConfigurationMethods.withInputDirectory(package.scala:44)\n  at geotrellis.spark.io.hadoop.package$withHadoopConfigurationMethods.withInputDirectory(package.scala:61)\n  at geotrellis.spark.io.hadoop.HadoopGeoTiffRDD$.configuration(HadoopGeoTiffRDD.scala:87)\n  at geotrellis.spark.io.hadoop.HadoopGeoTiffRDD$.apply(HadoopGeoTiffRDD.scala:114)\n  at geotrellis.spark.io.hadoop.HadoopGeoTiffRDD$.apply(HadoopGeoTiffRDD.scala:153)\n  at geotrellis.spark.io.hadoop.HadoopGeoTiffRDD$.multiband(HadoopGeoTiffRDD.scala:223)\n  at geotrellis.spark.io.hadoop.HadoopGeoTiffRDD$.spatialMultiband(HadoopGeoTiffRDD.scala:272)\n  at geotrellis.spark.io.hadoop.HadoopSparkContextMethods$class.hadoopMultibandGeoTiffRDD(HadoopSparkContextMethods.scala:98)\n  at geotrellis.spark.io.hadoop.Implicits$HadoopSparkContextMethodsWrapper.hadoopMultibandGeoTiffRDD(Implicits.scala:32)\n  at geotrellis.spark.io.hadoop.HadoopSparkContextMethods$class.hadoopMultibandGeoTiffRDD(HadoopSparkContextMethods.scala:85)\n  at geotrellis.spark.io.hadoop.Implicits$HadoopSparkContextMethodsWrapper.hadoopMultibandGeoTiffRDD(Implicits.scala:32)\n  ... 107 elided\n"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "3F8B2EE66589498691C5D8F0BDFB7A7A"
      },
      "cell_type" : "markdown",
      "source" : "# Prepare input for KMeans\n\nTo be able to run KMeans in Spark, we need to have RDD[Vector] as input"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "D917A9C17EA24F4C8CE15008D5CBF6A0"
      },
      "cell_type" : "code",
      "source" : [
        "// We convert multi tiles into one vector of features in RDD\n",
        "val rddArrayOfTiles = sourceTiles.map (l => (l._2.band(0).convert(DoubleConstantNoDataCellType).toArrayDouble(), \n",
        "                       l._2.band(1).convert(DoubleConstantNoDataCellType).toArrayDouble(), \n",
        "                       l._2.band(2).convert(DoubleConstantNoDataCellType).toArrayDouble(),\n",
        "                       l._2.band(3).convert(DoubleConstantNoDataCellType).toArrayDouble(), \n",
        "                       l._2.band(4).convert(DoubleConstantNoDataCellType).toArrayDouble(),\n",
        "                       l._2.band(5).convert(DoubleConstantNoDataCellType).toArrayDouble(), \n",
        "                       l._2.band(6).convert(DoubleConstantNoDataCellType).toArrayDouble(),\n",
        "                       l._2.band(7).convert(DoubleConstantNoDataCellType).toArrayDouble(),\n",
        "                       l._2.band(8).convert(DoubleConstantNoDataCellType).toArrayDouble(), \n",
        "                       l._2.band(9).convert(DoubleConstantNoDataCellType).toArrayDouble()))\n",
        ".map(l => l._1.zip(l._2).zip(l._3).zip(l._4).zip(l._5).zip(l._6).zip(l._7).zip(l._8).zip(l._9).zip(l._10))\n",
        ".map(l => l.map(k => Vectors.dense(k._1._1._1._1._1._1._1._1._1, k._1._1._1._1._1._1._1._1._2, \n",
        "                                   k._1._1._1._1._1._1._1._2, k._1._1._1._1._1._1._2,\n",
        "                                  k._1._1._1._1._1._2, k._1._1._1._1._2, k._1._1._1._2,\n",
        "                                   k._1._1._2, k._1._2, k._2)))"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:164: error: not found: value sourceTiles\n       val rddArrayOfTiles = sourceTiles.map (l => (l._2.band(0).convert(DoubleConstantNoDataCellType).toArrayDouble(),\n                             ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab1847339495-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "B2E98C85B4374893B473CBEBD596CAA2"
      },
      "cell_type" : "code",
      "source" : [
        "val input = rddArrayOfTiles.flatMap(l => l)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:161: error: not found: value rddArrayOfTiles\n       val input = rddArrayOfTiles.flatMap(l => l)\n                   ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "3911FDF110914D62B34D0716810DCC2B"
      },
      "cell_type" : "markdown",
      "source" : "# Build a KMeans model"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "D08F098506B748C28AD4BE607E6D74D4"
      },
      "cell_type" : "code",
      "source" : [
        "// We train KMeans model\n",
        "val clusters = KMeans.train(input, k, 20)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:164: error: not found: value input\n       val clusters = KMeans.train(input, k, 20)\n                                   ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "926D18D8CFFD431889A27844132F4DC7"
      },
      "cell_type" : "markdown",
      "source" : "# Save model to HDFS"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "831CADE201874E1E84C50138ADFC9BF5"
      },
      "cell_type" : "code",
      "source" : [
        "/*\n",
        "// Save model\n",
        "clusters.save(sc, saveAddress)\n",
        "*/"
      ],
      "outputs" : [
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 14,
          "time" : "Took: 1.958s, at 2019-02-04 09:59"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "C42CAD1987F94E1F8DA18FCAB80F3C8D"
      },
      "cell_type" : "markdown",
      "source" : "# Save model in PMML format"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "7C31B47CD8BF475C8F9EC6371BB50751"
      },
      "cell_type" : "code",
      "source" : [
        "// Export to PMML to a String in PMML format\n",
        "println(\"PMML Model:\\n\" + clusters.toPMML)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:164: error: not found: value clusters\n       println(\"PMML Model:\\n\" + clusters.toPMML)\n                                 ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "0CBD6E043272494789093D609AD7FFD6"
      },
      "cell_type" : "code",
      "source" : [
        "// Export the model to a directory on a distributed file system in PMML format\n",
        "clusters.toPMML(sc, saveAddressPmml)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "<console>:170: error: not found: value clusters\n       clusters.toPMML(sc, saveAddressPmml)\n       ^\n"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "3FBCD637ADDD4D3F87911211BDB7B3D2"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 17,
          "time" : "Took: 2.202s, at 2019-02-04 09:59"
        }
      ]
    }
  ],
  "nbformat" : 4
}