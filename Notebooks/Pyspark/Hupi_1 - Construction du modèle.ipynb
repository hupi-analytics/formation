{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "# Modèle d'analyse de sentiments - Sentiment analysis model\n",
    "\n",
    "\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sujet - Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de créer un modèle qui prédit le sentiment (positif/négatif) d'un texte donné. Pour cela, nous nous appuyons sur une base de données contenant environ 5700 commentaires de livres et leur sentiment.\n",
    "> \n",
    "*\n",
    "The purpose of this notebook is to create a model which can predict the feeling (positive/negative) of a text.\n",
    "For that, we will use a database with more than 5700 comments of books and their feeling.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme utilisé dans notre cas est la régression logistique. Cependant, vous verrez que le nombre de variables, correspondant aux mots utilisés, est très important. Nous utiliserons donc une régression logistique L-BFGS (Limited memory Broyden–Fletcher–Goldfarb–Shanno). Plutôt que d'utiliser la méthode de Newton-Raphson pour la recherche des coefficients optimaux, nous utiliserons une méthode Quasi-Newton. L'algorithme se base sur une estimation de la matrice hessienne (méthode BFGS). L-BFGS, contrairement à BFGS, stocke cette estimation avec seulement quelques vecteurs (representation implicite). Ceci nous permet de gagner en mémoire et en rapidité. Et donc nous pouvons lancer notre algorithme (en précisant le nombre d'iterations) sur un très grand nombre de variables.\n",
    "> \n",
    "*\n",
    "In our case, we will use the logistic regression model. However, we have a very big variable's number, the variables are the words that we have stored. We will use the logistic regression model with L-BFGS (Limited memory Broyden–Fletcher–Goldfarb–Shanno). Instead of using Newton-Raphson algorithm to calculate the coefficients, we will use a Quasi-Newton algorithm. This algorithm is based on an estimation of the Hessian matrix (BFGS). On contrary to BFGS, L-BFGS stores only a few vectors (implicit representation). With this, we save memory and we are faster. Finally, we can run our algorithm (indicating the iterations' number) on a big number of variables.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des libraries - Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data transformation\n",
    "from pyspark.mllib.linalg import Vectors  \n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "# for analyzing the results\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "# for logistic regression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.classification import LogisticRegressionModel\n",
    "\n",
    "# for SVM (for comparison)\n",
    "from pyspark.mllib.classification import SVMModel\n",
    "from pyspark.mllib.classification import SVMWithSGD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme du texte - Text formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons d'abord nettoyer le texte des accents, caractères spéciaux et autres.\n",
    "> \n",
    "*First of all, we have to clean the text from any accents, specials characters and others.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exemple', 'j', 'ai', 'reussi', 'a', 'nettoyer', 'et', 're', 'nettoyer', 'mon', 'texte']\n"
     ]
    }
   ],
   "source": [
    "def nettoyage_texte(text) :\n",
    "    texte = text.replace('À', 'A').replace('Á', 'A').replace('Â', 'A').replace('Ã', 'A') \\\n",
    "    .replace('È', 'E').replace('É', 'E').replace('Ê', 'E').replace('Ë', 'E') \\\n",
    "    .replace('Í', 'I').replace('Ì', 'I').replace('Î', 'I').replace('Ï', 'I') \\\n",
    "    .replace('Ù', 'U').replace('Ú', 'U').replace('Û', 'U').replace('Ü', 'U') \\\n",
    "    .replace('Ò', 'O').replace('Ó', 'O').replace('Ô', 'O').replace('Õ', 'O') \\\n",
    "    .replace('Ö', 'O').replace('Ñ', 'N').replace('Ç', 'C').replace('ª', 'A') \\\n",
    "    .replace('º', 'O').replace('§', 'S').replace('³', '3').replace('²', '2') \\\n",
    "    .replace('¹', '1').replace('à', 'a').replace('á', 'a').replace('â', 'a') \\\n",
    "    .replace('ã', 'a').replace('ä', 'a').replace('è', 'e').replace('é', 'e') \\\n",
    "    .replace('ê', 'e').replace('ë', 'e').replace('í', 'i').replace('ì', 'i') \\\n",
    "    .replace('î', 'i').replace('ï', 'i').replace('ù', 'u').replace('ú', 'u') \\\n",
    "    .replace('û', 'u').replace('ü', 'u').replace('ò', 'o').replace('ó', 'o') \\\n",
    "    .replace('ô', 'o').replace('õ', 'o').replace('ö', 'o').replace('ñ', 'n') \\\n",
    "    .replace('Ä', 'A').replace('ç', 'c') \\\n",
    "    .replace(\"!\",\" \").replace(\".\",\" \").replace(\"?\",\" \").replace(\",\",\" \") \\\n",
    "    .replace(\";\",\" \").replace(\":\",\" \").replace(\"/\",\" \").replace(\"+\",\" \") \\\n",
    "    .replace(\"%\",\" \").replace(\"(\",\" \").replace(\")\",\" \").replace(\"[\",\" \") \\\n",
    "    .replace(\"]\",\" \").replace(\"&\",\" \").replace(\"`\",\" \").replace(\"*\",\" \") \\\n",
    "    .replace(\"$\",\" \").replace(\"«\",\" \").replace(\"»\",\" \").replace(\"'\",\" \") \\\n",
    "    .replace(\"_\",\" \").replace(\"\\t\",\" \").replace(\"|\",\" \").replace(\"\\\"\",\" \") \\\n",
    "    .replace(\"0\",\" \").replace(\"1\",\" \").replace(\"2\",\" \").replace(\"3\",\" \") \\\n",
    "    .replace(\"4\",\" \").replace(\"5\",\" \").replace(\"6\",\" \").replace(\"7\",\" \") \\\n",
    "    .replace(\"8\",\" \").replace(\"9\",\" \") \\\n",
    "    .replace(\"!\",\" \").replace(\".\",\" \").replace(\"?\",\" \").replace(\",\",\" \") \\\n",
    "    .replace(\";\",\" \").replace(\":\",\" \").replace(\"/\",\" \").replace(\"+\",\" \") \\\n",
    "    .replace(\"%\",\" \").replace(\"(\",\" \").replace(\")\",\" \").replace(\"[\",\" \") \\\n",
    "    .replace(\"]\",\" \").replace(\"&\",\" \").replace(\"`\",\" \").replace(\"*\",\" \") \\\n",
    "    .replace(\"$\",\" \").replace(\"«\",\" \").replace(\"»\",\" \").replace(\"'\",\" \") \\\n",
    "    .replace(\"_\",\" \").replace(\"\\t\",\" \").replace(\"|\",\" \").replace(\"\\\"\",\" \") \\\n",
    "    .replace(\" -\",\" \").replace(\"- \",\" \").replace(\"--\",\" \").replace(\" - \",\" \") \\\n",
    "    .lower().strip().split()\n",
    "    return texte\n",
    "\n",
    "texte = nettoyage_texte(\"Ëxémplè : J'äï$ réùssî à néttöyer- et re- néttöyer môn 1 téxtè !\")\n",
    "print(texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, il faut mettre en forme le texte pour que le modèle puisse lire les données\n",
    "> *Then, we have to format the text so that the model can read the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mise_en_forme(liste_mots, texte, sentiment = 1):\n",
    "    data = zip(texte, [texte.count(w) for w in texte]) # Contage des mots du texte (effectifs)\n",
    "    data = list(set(data))  # Retrait des doublons\n",
    "    data = [w for w in data if (w[0],0) in liste_mots] # Filtre les mots retenus précédemment (dans liste_mots)\n",
    "    # Ajout des mots retenus qui ne sont pas présents dans la phrase sous la forme: (mot,0)\n",
    "    data = data +[ w for w in liste_mots if w[0] not in [x[0] for x in data] ]\n",
    "    data = sorted(data, key=lambda l: l[0])  # On trie par ordre alphabétique des mots\n",
    "    data = LabeledPoint( sentiment ,Vectors.dense([w[1] for w in data]) )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la base de données - Loading the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Il n'est inutile de preciser que l'auteur est suisse, et qu'il ne s'agit pas d'une traduction, mais d'un roman noir, se deroulant aux etats-Unis, avec des codes tres etatsuniens, mais tournes en derision. Car, apres lecture d'autres commentaires, je trouve qu'on oublie de dire que, parfois, c'est tres drole (si, si, j'ai eclate de rire plusieurs fois en le lisant) - a d'autres moments, on est dans une enquete tres serieuse. Pour tout dire, j'ai parfois eu l'impression de me retrouver dans Fargo des freres Coen : tous les protagonistes se comportent tous a un moment ou a un autre comme de sombres cretins, meme si ce qui arrive est tragique. Harry Quebert n'y echappe pas tant on se demande bien comment il a pu tomber amoureux d'une Nola dont on peine a percevoir les qualites tout au long du roman (s'il devait y avoir un cote roman d'amour, de ce cote, c'est rate, mais ce n'etait peut-etre pas du tout le but...). Outre Fargo, une autre reference pourrait etre Twin Peaks. Le style a ete critique par certains - a raison pour partie - mais attention, il n'est pas dit que parfois il ne s'agisse pas de formulations volontairement choisies par l'auteur pour parodier une mauvaise traduction (ce qu'est, quand meme, cense etre ce roman, fait a la va-vite que je te pousse sous l'influence de l'editeur Schmid & Hanson, dont l'ambition semble etre de flinguer la litterature - sans colt). Par contre, la construction du roman est assez impressionnante, et l'histoire prenante (avec un petit coup de mou vers la moitie, pour mieux rebondir par la suite). Au fond, ce n'est pas un chef d'oeuvre mais un excellent roman, bien superieur a ceux qu'il parodie. On a un ecrivain qui veut raconter une histoire, et qui le fait tres bien. Lisez-le, avec a l'esprit son cote parodique et pour son cote plus sombre.\",\n",
       " '|Positive|')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donnees=sc.textFile(\"hdfs://ecoles.node1.pro.hupi.loc/user/anthony.laffond/CommentairesLivres5000_pr.csv\",use_unicode=False) \\\n",
    "          .map( lambda l : ( l[0:(len(l)-10)] , l[(len(l)-10):len(l)] ) ) \\\n",
    "          .persist()\n",
    "n= donnees.count()\n",
    "donnees.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage de la base de données - Database cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['il', 'n', 'est', 'inutile', 'de', 'preciser', 'que', 'l', 'auteur', 'est', 'suisse', 'et', 'qu', 'il', 'ne', 's', 'agit', 'pas', 'd', 'une', 'traduction', 'mais', 'd', 'un', 'roman', 'noir', 'se', 'deroulant', 'aux', 'etats-unis', 'avec', 'des', 'codes', 'tres', 'etatsuniens', 'mais', 'tournes', 'en', 'derision', 'car', 'apres', 'lecture', 'd', 'autres', 'commentaires', 'je', 'trouve', 'qu', 'on', 'oublie', 'de', 'dire', 'que', 'parfois', 'c', 'est', 'tres', 'drole', 'si', 'si', 'j', 'ai', 'eclate', 'de', 'rire', 'plusieurs', 'fois', 'en', 'le', 'lisant', 'a', 'd', 'autres', 'moments', 'on', 'est', 'dans', 'une', 'enquete', 'tres', 'serieuse', 'pour', 'tout', 'dire', 'j', 'ai', 'parfois', 'eu', 'l', 'impression', 'de', 'me', 'retrouver', 'dans', 'fargo', 'des', 'freres', 'coen', 'tous', 'les', 'protagonistes', 'se', 'comportent', 'tous', 'a', 'un', 'moment', 'ou', 'a', 'un', 'autre', 'comme', 'de', 'sombres', 'cretins', 'meme', 'si', 'ce', 'qui', 'arrive', 'est', 'tragique', 'harry', 'quebert', 'n', 'y', 'echappe', 'pas', 'tant', 'on', 'se', 'demande', 'bien', 'comment', 'il', 'a', 'pu', 'tomber', 'amoureux', 'd', 'une', 'nola', 'dont', 'on', 'peine', 'a', 'percevoir', 'les', 'qualites', 'tout', 'au', 'long', 'du', 'roman', 's', 'il', 'devait', 'y', 'avoir', 'un', 'cote', 'roman', 'd', 'amour', 'de', 'ce', 'cote', 'c', 'est', 'rate', 'mais', 'ce', 'n', 'etait', 'peut-etre', 'pas', 'du', 'tout', 'le', 'but', 'outre', 'fargo', 'une', 'autre', 'reference', 'pourrait', 'etre', 'twin', 'peaks', 'le', 'style', 'a', 'ete', 'critique', 'par', 'certains', 'a', 'raison', 'pour', 'partie', 'mais', 'attention', 'il', 'n', 'est', 'pas', 'dit', 'que', 'parfois', 'il', 'ne', 's', 'agisse', 'pas', 'de', 'formulations', 'volontairement', 'choisies', 'par', 'l', 'auteur', 'pour', 'parodier', 'une', 'mauvaise', 'traduction', 'ce', 'qu', 'est', 'quand', 'meme', 'cense', 'etre', 'ce', 'roman', 'fait', 'a', 'la', 'va-vite', 'que', 'je', 'te', 'pousse', 'sous', 'l', 'influence', 'de', 'l', 'editeur', 'schmid', 'hanson', 'dont', 'l', 'ambition', 'semble', 'etre', 'de', 'flinguer', 'la', 'litterature', 'sans', 'colt', 'par', 'contre', 'la', 'construction', 'du', 'roman', 'est', 'assez', 'impressionnante', 'et', 'l', 'histoire', 'prenante', 'avec', 'un', 'petit', 'coup', 'de', 'mou', 'vers', 'la', 'moitie', 'pour', 'mieux', 'rebondir', 'par', 'la', 'suite', 'au', 'fond', 'ce', 'n', 'est', 'pas', 'un', 'chef', 'd', 'oeuvre', 'mais', 'un', 'excellent', 'roman', 'bien', 'superieur', 'a', 'ceux', 'qu', 'il', 'parodie', 'on', 'a', 'un', 'ecrivain', 'qui', 'veut', 'raconter', 'une', 'histoire', 'et', 'qui', 'le', 'fait', 'tres', 'bien', 'lisez-le', 'avec', 'a', 'l', 'esprit', 'son', 'cote', 'parodique', 'et', 'pour', 'son', 'cote', 'plus', 'sombre'], 1)\n"
     ]
    }
   ],
   "source": [
    "texte = donnees.map( lambda l : (nettoyage_texte(l[0]),nettoyage_texte(l[1])) ) \\\n",
    "               .map( lambda l : (l[0], (l[1]==[\"positive\"])*1) ).persist() \n",
    "n= texte.count()\n",
    "print(texte.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un dictionnaire - Dictionnary creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons besoin de créer un dictionnaire de mots qui définira nos variables\n",
    "> \n",
    "*We have to create a dictionnary which will define our variables (features)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots sur l'ensemble des données : 27218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('abandon', 14),\n",
       " ('abandonnant', 3),\n",
       " ('abandonne', 39),\n",
       " ('abandonnee', 7),\n",
       " ('abandonnent', 2)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Occurence des mots sur la BD / Word Occurence on the DB\n",
    "selection = sorted ( texte.flatMap(lambda l : l[0]).groupBy(lambda w : w) \\\n",
    "                 .map( lambda l : (l[0],len(l[1])) ).collect() )\n",
    "print(\"nombre de mots sur l'ensemble des données : \" + str(len(selection)) )\n",
    "selection[25:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de StopWords : 218\n"
     ]
    }
   ],
   "source": [
    "# Importation de la base de StopWords / StopWords list import\n",
    "stopwords = sc.textFile(\"hdfs://ecoles.node1.pro.hupi.loc/user/anthony.laffond/StopWordsCleanWN.txt\",use_unicode=False).collect()\n",
    "print(\"Nombre de StopWords : \"+ str(len(stopwords)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots retenus : 2668\n"
     ]
    }
   ],
   "source": [
    "min_eff = 20\n",
    "liste_mots = sorted([ (w[0],0) for w in selection if ( (w[1]>min_eff) and (w[0] not in stopwords) )])\n",
    "print(\"Nombre de mots retenus : \" + str(len(liste_mots)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('an', 0), ('analyse', 0), ('analyser', 0), ('analyses', 0), ('ancien', 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_mots[200:205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.parallelize(sorted([x[0] for x in liste_mots])) \\\n",
    "  .saveAsTextFile(\"hdfs://ecoles.node1.pro.hupi.loc/user/anthony.laffond/my_liste4700py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme des données - Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la base de données : 5470\n"
     ]
    }
   ],
   "source": [
    "data = texte.map( lambda l : mise_en_forme(liste_mots, l[0] ,l[1]) )\n",
    "n_data = data.count()\n",
    "print( \"Taille de la base de données : \"+str(n_data) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apprentissage/Validation - Training/Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va découper notre base de données en un échantillon d'apprentissage (80% pour la construction du modèle) et un échantillon de test (20% pour le calcul d'indicateurs de qualité du modèle). \n",
    "> \n",
    "*We are going to split our database into a training dataset (80% to build the model) and a test dataset (20% to calculate features of model quality)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'échantillon d'apprentissage : 4342\n",
      "Taille de l'échantillon de test : 1128\n"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.8, 0.2], seed = 1234)\n",
    "training = splits[0].cache()\n",
    "test = splits[1].cache()\n",
    "\n",
    "n_training = training.count()\n",
    "n_test = test.count()\n",
    "print( \"Taille de l'échantillon d'apprentissage : \" + str(n_training) )\n",
    "print( \"Taille de l'échantillon de test : \" + str(n_test) )\n",
    "\n",
    "# Le découpage en 2 échantillons est plutôt long comparé à Scala / the split in 2 parts is longer than in Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de positif dans la base de données : 0.731992687386\n",
      "Taux de positif dans l'échantillon d'apprentissage : 0.730769230769\n",
      "Taux de positif dans l'échantillon de test : 0.73670212766\n"
     ]
    }
   ],
   "source": [
    "print( \"Taux de positif dans la base de données : \" + str(data.map(lambda l: l.label).sum()/float(n_data)) ) \n",
    "print( \"Taux de positif dans l'échantillon d'apprentissage : \" + str(training.map(lambda l: l.label).sum()/float(n_training) ) )\n",
    "print( \"Taux de positif dans l'échantillon de test : \" + str(test.map(lambda l: l.label).sum()/float(n_test) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression logistique - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(training, numClasses=2, iterations=1000) # Training\n",
    "model.clearThreshold() # permet d'obtenir le score (et non directement le sentiment attribué)\n",
    "                       #  - it allows us to get the score and not the sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du taux d'erreur - Calculating the error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de positif mal prédit : 0.0328014184397\n",
      "Taux de négatif mal prédit : 0.0310283687943\n",
      "Taux de positif bien prédit : 0.70390070922\n",
      "Taux de négatif bien prédit : 0.232269503546\n",
      "Taux d'erreur : 0.063829787234\n"
     ]
    }
   ],
   "source": [
    "# Sur l'échantillon test - On the test dataset\n",
    "scoreAndLabels = test.map(lambda l : ( (model.predict(l.features)>0.5)*1.0 , l.label) )\n",
    "\n",
    "taux_p = scoreAndLabels.map(lambda l: ( (l[0]==0) and (l[1]==1) )*1 ).reduce(lambda x,y : x+y )\n",
    "taux_n = scoreAndLabels.map(lambda l: ( (l[0]==1) and (l[1]==0) )*1 ).reduce(lambda x,y : x+y )\n",
    "taux_pb = scoreAndLabels.map(lambda l: ( (l[0]==1) and (l[1]==1) )*1 ).reduce(lambda x,y : x+y )\n",
    "taux_nb = scoreAndLabels.map(lambda l: ( (l[0]==0) and (l[1]==0) )*1 ).reduce(lambda x,y : x+y )\n",
    "taux_err = scoreAndLabels.map(lambda l: (l[0]!=l[1])*1 ).reduce(lambda x,y : x+y )\n",
    "\n",
    "print(\"Taux de positif mal prédit : \" + str(taux_p/float(n_test)) )\n",
    "print(\"Taux de négatif mal prédit : \" + str(taux_n/float(n_test)) )\n",
    "print(\"Taux de positif bien prédit : \" + str(taux_pb/float(n_test)) )\n",
    "print(\"Taux de négatif bien prédit : \" + str(taux_nb/float(n_test)) )\n",
    "print(\"Taux d'erreur : \" + str(taux_err/float(n_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de l'AUC - Calculating the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.918815106541\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(scoreAndLabels)\n",
    "AUC = metrics.areaUnderROC\n",
    "print(\"Area under ROC = \" + str(AUC) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle - Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(sc, \"hdfs://ecoles.node1.pro.hupi.loc/user/anthony.laffond/model_reglog2600py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PMML : doesn't exist yet\n",
    "#model.toPMML(sc,\"hdfs://ecoles.node1.pro.hupi.loc/user/anthony.laffond/model_reglog_PMML2600py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3G",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
